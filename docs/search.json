[
  {
    "objectID": "risk_and_return.html",
    "href": "risk_and_return.html",
    "title": "Estimating Risk and Return",
    "section": "",
    "text": "Estimating risks and returns is probably the most important - and the most difficult - topic in quantitative finance. There are plenty of approaches to tackle it.\nBelow is a series of articles delving into various approaches and techniques to analyse time series and estimating risk and returns. This list will be augmented over time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate Financial Risk\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "all_posts.html",
    "href": "all_posts.html",
    "title": "All Posts",
    "section": "",
    "text": "Vincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n1-a Setting up a Python Development Workstation (MacOs)\n\n\n\n\n\n\n101\n\n\nen\n\n\nsetup\n\n\npython\n\n\nbash\n\n\nmacos\n\n\nmatplotlib\n\n\n\nIn this article, we start our journey into Finance and Python coding. Let’s set up our MacOs Workstation and install a few key tools to code efficiently.\n\n\n\n\n\nFeb 20, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n1-b- Setting up a Python Development Workstation (Windows)\n\n\n\n\n\n\n101\n\n\nen\n\n\nsetup\n\n\nbash\n\n\npython\n\n\nwindows\n\n\nmatplotlib\n\n\n\nIn this article we set up our Windows workstation and install all the relevant tools to be efficient in coding in Python.\n\n\n\n\n\nFeb 22, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n15/07/2024: Economics, Indexing, Quant and Coding Links\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n2 - Getting and charting data with Matplotlib\n\n\n\n\n\n\ntutorial\n\n\ndata\n\n\nmatplotlib\n\n\nen\n\n\n\nIn this article, we start our data analysis journey with Python by getting and charting data, in this case the performance of an ETF using freely available data.\n\n\n\n\n\nJan 25, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n4 - First Macro-Economic data analysis: using the Eurostat API\n\n\n\n\n\n\nen\n\n\n101\n\n\ndata\n\n\napi\n\n\ndata\n\n\npython\n\n\nmacro\n\n\neconomics\n\n\n\nIn this article, we leverage our first API request, using the data provided freely by the Eurostat organisation.\n\n\n\n\n\nJan 15, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Equity long Term Returns with Python\n\n\n\n\n\n\ntutorial\n\n\nlong term investing\n\n\nen\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate Financial Risk\n\n\n\n\n\n\ndata-gathering\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Worldbank API (WBGAPI)\n\n\n\n\n\n\n101\n\n\nen\n\n\n\n\n\n\n\n\n\nApr 5, 2023\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nLes 10 formules les plus utilisées en finance de marché\n\n\n\n\n\n\nfr\n\n\nfinance\n\n\ntutorial\n\n\n101\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nObtenir la valorisation de plusieurs titres avec Python et Alpha Vantage\n\n\n\n\n\n\nfr\n\n\nvaluation\n\n\nfundamental\n\n\n\n\n\n\n\n\n\nApr 1, 2023\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nPortfolio Construction\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nPortfolio optimisation with Python\n\n\n\n\n\n\nportfolio-construction\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nUsing WBGAPI: A Step-By-Step Guide to Access World Bank Data\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising Historical Data\n\n\n\n\n\n\npublication-workflow\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introductory Videos",
    "section": "",
    "text": "With 20+ years of experience in portfolio construction, asset allocation and quantitative research, I have worked across the entire asset management and financial markets value chain.\nIn this blog, I document my findings and experiments, notably in Python, Jupyter and along themes like portfolio optimisation and reproducible research.\nIn particular, this section provides you with a Zero to Hero experience in Python and Quantitative Finance.\n\n\n\n\nThe Data Driven Minutes\n\n\n\n\n\nDaily Quant & Coding Curation\n\n\n\n\n\nAll Tutorials\nGetting Started: Mac\nGetting Started: Windows PC\n\n\n\n\n\nPortfolio Optimisation with Python\nRisks and Returns 101\n\n\n\n\n\nQuarto: a revolution in the scientific blogging and publication workflow\n\n\n\n\n\nPowerful Word document Generation with python\nAutomated Powerpoint authoring with python\nNice Pictures with Python and Matplotlib"
  },
  {
    "objectID": "index.html#welcome-to-portfolio-geek",
    "href": "index.html#welcome-to-portfolio-geek",
    "title": "Introductory Videos",
    "section": "",
    "text": "With 20+ years of experience in portfolio construction, asset allocation and quantitative research, I have worked across the entire asset management and financial markets value chain.\nIn this blog, I document my findings and experiments, notably in Python, Jupyter and along themes like portfolio optimisation and reproducible research.\nIn particular, this section provides you with a Zero to Hero experience in Python and Quantitative Finance."
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#introduction",
    "href": "posts/tutorials/en/shiller-data-python.html#introduction",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Introduction",
    "text": "Introduction\nLong Term Investing enables investors to capture the long term risk premium of various asset classes.\nIn this article, we will explore how to download Shiller’s Excel data on long-term stock market returns from his website using Python. We will use the requests library for HTTP requests and the pandas library for data manipulation. For visualization, we will use the Matplotlib library with the Pacoty stylesheet to create a chart comparing nominal equity returns, real equity returns, and real GDP growth."
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#downloading-shillers-data",
    "href": "posts/tutorials/en/shiller-data-python.html#downloading-shillers-data",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Downloading Shiller’s Data",
    "text": "Downloading Shiller’s Data\nFirst, we need to import the required libraries and download the data using an HTTP request:\nThis code below downloads the Excel file from Shiller’s website, directly into memory, and reads it into a pandas DataFrame.\n\n\nCode\nimport requests\nimport pandas as pd\nfrom io import BytesIO\nimport dataframe_image as dfi\n\nurl = \"http://www.econ.yale.edu/~shiller/data/ie_data.xls\"\n\nresponse = requests.get(url)\n\ndef make_pretty(styler):\n    styler.format(precision=2)\n    return styler\n\n# Check if the request was successful\nif response.status_code == 200:\n    data = pd.read_excel(BytesIO(response.content), sheet_name='Data', header=7)\nelse:\n    print(\"Failed to download the data\")\n\ndata.iloc[1:10, 1:5].style.pipe(make_pretty)\n\n\n\n\n\n\n\n\n\n \nP\nD\nE\nCPI\n\n\n\n\n1\n4.50\n0.26\n0.40\n12.84\n\n\n2\n4.61\n0.26\n0.40\n13.03\n\n\n3\n4.74\n0.26\n0.40\n12.56\n\n\n4\n4.86\n0.26\n0.40\n12.27\n\n\n5\n4.82\n0.26\n0.40\n12.08\n\n\n6\n4.73\n0.26\n0.40\n12.08\n\n\n7\n4.79\n0.26\n0.40\n11.89\n\n\n8\n4.84\n0.26\n0.40\n12.18\n\n\n9\n4.59\n0.26\n0.40\n12.37"
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#downloading-maddison-project-gdp-data",
    "href": "posts/tutorials/en/shiller-data-python.html#downloading-maddison-project-gdp-data",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Downloading Maddison Project GDP Data",
    "text": "Downloading Maddison Project GDP Data\n\n\nCode\nurl = \"https://www.rug.nl/ggdc/historicaldevelopment/maddison/data/mpd2020.xlsx\"\n\nresponse = requests.get(url)\n\ndef make_pretty(styler):\n    styler.format(precision=2)\n    return styler\n\n# Check if the request was successful\nif response.status_code == 200:\n    data_gdp= pd.read_excel(BytesIO(response.content),sheet_name=\"Full data\", header=0)\nelse:\n    print(\"Failed to download the data\")\n\n\n\n\nCode\nimport numpy.ma as ma\ndata_gdp[\"gdp\"] = data_gdp.gdppc * data_gdp[\"pop\"]\ndates = ma.array(\n    [f'{y}-{12}-{31}' for y in data_gdp.year.to_list()],\n    dtype='datetime64[D]'\n    )\n\ndata_gdp[\"date\"] = dates.tolist()\ndata_gdp.set_index(\"date\", inplace=True)\ndata_gdp.iloc[1:10, 1:5].style.pipe(make_pretty)\n\n\n\n\n\n\n\n\n \ncountry\nyear\ngdppc\npop\n\n\ndate\n \n \n \n \n\n\n\n\n1870-12-31\nAfghanistan\n1870\nnan\n4207.00\n\n\n1913-12-31\nAfghanistan\n1913\nnan\n5730.00\n\n\n1950-12-31\nAfghanistan\n1950\n1156.00\n8150.00\n\n\n1951-12-31\nAfghanistan\n1951\n1170.00\n8284.00\n\n\n1952-12-31\nAfghanistan\n1952\n1189.00\n8425.00\n\n\n1953-12-31\nAfghanistan\n1953\n1240.00\n8573.00\n\n\n1954-12-31\nAfghanistan\n1954\n1245.00\n8728.00\n\n\n1955-12-31\nAfghanistan\n1955\n1246.00\n8891.00\n\n\n1956-12-31\nAfghanistan\n1956\n1278.00\n9062.00"
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#cleanup-and-columns-renaming",
    "href": "posts/tutorials/en/shiller-data-python.html#cleanup-and-columns-renaming",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Cleanup and Columns Renaming",
    "text": "Cleanup and Columns Renaming\n\n\nCode\n#Excel Import is mixing up columns, re-titling them\ndata.columns = [\"Date\", \"S&P Composite\", \"Dividend (D)\", \"Earnings (E)\", \"Consumer Price Index (CPI)\", \"Date Fraction\", \"Long Interest Rate (I)\", \"Real Price\", \"Real Dividend\", \"Real Total Return Price\", \"Real Earnings\", \"Real TR Scaled Earnings\", \"CAPE\", \"\", \"TR CAPE\", \"\", \"Excess CAPE Yield\", \"Monthly Total Bond Returns\", \"Real Total Bond Returns\", \"10Y Ann Stock Real Return\", \"10Y Ann Bon Real Return\", \"Real 10Y Ann Excess Return\"]\ndata = data[:-2]\ndata[\"date\"] = pd.to_datetime(data['Date'].map('{:.2f}'.format), format='%Y.%m')\ndata.set_index(\"date\", inplace=True)\ndata[\"Price Return\"] = data[\"Real Price\"].div(data[\"Real Price\"].iloc[0])\ndata[\"Total Return\"] = data.loc[:, \"Real Total Return Price\"].div(data[\"Real Total Return Price\"].iloc[0])\ndata[\"CPI\"] = data.loc[:, \"Consumer Price Index (CPI)\"].div(data[\"Consumer Price Index (CPI)\"].iloc[0])"
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#visualizing-the-data-with-matplotlib-and-pacoty",
    "href": "posts/tutorials/en/shiller-data-python.html#visualizing-the-data-with-matplotlib-and-pacoty",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Visualizing the Data with Matplotlib and Pacoty",
    "text": "Visualizing the Data with Matplotlib and Pacoty\nNext, we will create a chart comparing the nominal equity returns, real equity returns, and real GDP growth using Matplotlib and the Pacoty. Let’s start with a first sanity check on the data.\n\n\n\nDataframe\n\n\nThis code snippet creates a chart with a logarithmic scale, comparing nominal equity returns, real equity returns, and real GDP growth over time."
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#long-term-equity-returns",
    "href": "posts/tutorials/en/shiller-data-python.html#long-term-equity-returns",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Long Term Equity Returns",
    "text": "Long Term Equity Returns\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy import interpolate\nimport highlight_text as ht\nfrom highlight_text import HighlightText, ax_text, fig_text\nimport matplotlib.dates as mdates\nimport datetime as dt\nfrom scipy import stats\n\n\ndef decyear4(year, month, day, h=0, m=0, s=0):\n    return year + ((30.4375*(month-1) + day-1)*24+h)*3600/31557600.0 \n\n# Set the Pacoty stylesheet\nmpl_style = \"revealjs_whiteboard\"\nplt.style.use(f'../../stylesheets/{mpl_style}.mplstyle')\n\n# Create a figure and axis\nfig, ax = plt.subplots()\n \n# Extract the data we need\nus_gdp = data_gdp[data_gdp.countrycode == \"USA\"].gdp\ndates = data[[\"Real Price\"]].resample(\"Y\").last().index\nus_gdp.index = [dt.datetime.combine(dat, dt.time()) for dat in us_gdp.index]\nus_gdp = us_gdp[us_gdp.index &gt;= dates.min()]\nus_gdp = us_gdp / us_gdp.iloc[0]\nreal_tr = list(data['Price Return'].resample(\"Y\").last().values)\nreal_pr = list(data[\"Total Return\"].resample(\"Y\").last().values)\ncpi = list(data[\"CPI\"].resample(\"Y\").last().values)\n\n#gdp_growth = data['Real GDP Growth']\n\n# Plot the data on a logarithmic scale\n\nf_real_tr= interpolate.interp1d(dates.year, real_tr, 'cubic')\nf_real_pr = interpolate.interp1d(dates.year, real_pr, 'cubic')\n\nreal_tr_interpol = f_real_tr(dates.year)\nreal_pr_interpol = f_real_pr(dates.year)\n\nstats.linregress(dates.year, real_tr)\n\nax.semilogy(dates, real_pr_interpol)\nax.semilogy(dates, real_tr_interpol)\nax.semilogy(us_gdp.index, us_gdp)\n#ax.semilogy(dates, cpi)\n\n#ax.semilogy(years, data[])\n\nsize = plt.rcParams['font.size']\nhighlight_textprops =[{\"fontsize\": size + 4},\n                      {\"fontsize\": size}]\n\nHighlightText(x=0.5, y=0.98, ha='center', \n              s='&lt;Long Term Equity Returns&gt;\\n&lt;Equity vs GDP Growth and Inflation&gt;',\n              highlight_textprops=highlight_textprops,\n              annotationbbox_kw={'boxcoords': fig.transFigure}, textalign=\"center\")\n\n# Customize the chart\nax.set_xlabel('Years')\nax.set_ylabel(f'Value, basis 1 in {(data.index.min().strftime(\"%d.%m.%Y\"))}')\n#ax.set_title('Long Term Equity Returns')\nfig.legend(labels = [\"US Equity: Price (Real)\", \"US Equity: Price & Divs (Real)\", \"US GDP (Real)\"], loc=\"lower left\", ncol=2, bbox_to_anchor=(0.05, -0.075, 0.5, 0.5))\nax.xaxis.set_major_locator(mdates.YearLocator(30))\nax.xaxis.set_major_formatter(\n    mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n\n# Show the chart\nplt.show()\nplt.close()\n#fig.savefig(\"shiller-returns.png\")  \n\n\n\n\n\nLong term equity returns vs CPI\n\n\n\n\nThe resulting chart demonstrates the power of compounded returns and the equity risk premium that has rewarded long-term shareholders. By using Python libraries like requests, pandas, and Matplotlib, we can easily download, process, and visualize financial data to better understand market trends and investment strategies."
  },
  {
    "objectID": "posts/tutorials/en/spy-and-matplotlib.html",
    "href": "posts/tutorials/en/spy-and-matplotlib.html",
    "title": "2 - Getting and charting data with Matplotlib",
    "section": "",
    "text": "Welcome to the second episode of our Python and Quantitative Finance tutorial, where we will enter in our real Python journey.\nIn this first coding exercise, things will be very simple, we will essentially look at the past performance of a financial tool, an ETF. This ETF is called the SPY, it’s a US domiciled ETF that aims to replicate the performance of the S&P 500 Index1, one of the key indices to measure the performance of the US Equity market."
  },
  {
    "objectID": "posts/tutorials/en/spy-and-matplotlib.html#introduction",
    "href": "posts/tutorials/en/spy-and-matplotlib.html#introduction",
    "title": "2 - Getting and charting data with Matplotlib",
    "section": "",
    "text": "Welcome to the second episode of our Python and Quantitative Finance tutorial, where we will enter in our real Python journey.\nIn this first coding exercise, things will be very simple, we will essentially look at the past performance of a financial tool, an ETF. This ETF is called the SPY, it’s a US domiciled ETF that aims to replicate the performance of the S&P 500 Index1, one of the key indices to measure the performance of the US Equity market."
  },
  {
    "objectID": "posts/tutorials/en/spy-and-matplotlib.html#import-libraries",
    "href": "posts/tutorials/en/spy-and-matplotlib.html#import-libraries",
    "title": "2 - Getting and charting data with Matplotlib",
    "section": "Import Libraries",
    "text": "Import Libraries\nFirst, we import necessary libraries. yfinance will fetch the data, and matplotlib will help us chart it.\n\n\nCode\nimport yfinance as yf\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/tutorials/en/spy-and-matplotlib.html#footnotes",
    "href": "posts/tutorials/en/spy-and-matplotlib.html#footnotes",
    "title": "2 - Getting and charting data with Matplotlib",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor more information on the S&P 500 Index, you can look at this Wikipedia article.↩︎\nFor more information on the pandas library, look at its reference website.↩︎"
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-windows.html",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-windows.html",
    "title": "1-b- Setting up a Python Development Workstation (Windows)",
    "section": "",
    "text": "Welcome, fellow data enthusiasts and future quants! Today, we embark on an exciting journey to set up a coding environment that bridges the gap between mathematical theory and the practical world of finance. Whether you’re a student stepping into the field or a practitioner eager to enhance your skills, this guide is your first step towards mastering quantitative finance with Python. Let’s demystify the process and make it enjoyable together."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#introduction",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#introduction",
    "title": "1-b- Setting up a Python Development Workstation (Windows)",
    "section": "",
    "text": "Welcome, fellow data enthusiasts and future quants! Today, we embark on an exciting journey to set up a coding environment that bridges the gap between mathematical theory and the practical world of finance. Whether you’re a student stepping into the field or a practitioner eager to enhance your skills, this guide is your first step towards mastering quantitative finance with Python. Let’s demystify the process and make it enjoyable together."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#general-setup",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#general-setup",
    "title": "1-b- Setting up a Python Development Workstation (Windows)",
    "section": "1 General Setup",
    "text": "1 General Setup\n\n1.1 Setting Up Chocolatey\nOpen an administrator PowerShell and execute:\nSet-ExecutionPolicy Bypass -Scope Process -Force; \n[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; \niwr https://chocolatey.org/install.ps1 -UseBasicParsing | iex\n\n\n1.2 Setting Up Powershell, Visual Studio Code, and Miniconda\nWhy this trio? Powershell for a superior shell experience, Visual Studio Code (VS Code) for its versatility as a code editor, and Miniconda for managing our Python environments efficiently.\n# Install Zsh, VS Code, and Miniconda\n\nchoco install vscode miniconda3 -y\nTo setup the conda integration for Powershell, once a powershell windows is opened, you can type conda init, this will enable an easier monitoring of the virtual environment."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#visual-studio-code-setup-installing-key-visual-studio-extensions",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#visual-studio-code-setup-installing-key-visual-studio-extensions",
    "title": "1-b- Setting up a Python Development Workstation (Windows)",
    "section": "2. Visual Studio Code Setup: Installing Key Visual Studio Extensions",
    "text": "2. Visual Studio Code Setup: Installing Key Visual Studio Extensions\nVS Code shines with its extensions. Here are a few that will make your life easier:\n\nPython: Gives you a host of Python-specific features like linting, debugging, code formatting, and more.\nPrettier: A code formatter that supports many languages, including Python. Keeps your code clean and professional.\nCode Spell Checker: Like a proof-reader, it catches common spelling mistakes in your code.\n\nYou can install these extensions by searching for them in the VS Code Extensions view (Ctrl + Shift + X) and clicking on “Install”."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#create-a-conda-virtual-environment",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#create-a-conda-virtual-environment",
    "title": "1-b- Setting up a Python Development Workstation (Windows)",
    "section": "3: Create a Conda Virtual Environment",
    "text": "3: Create a Conda Virtual Environment\nWhy a virtual environment? It allows us to create isolated spaces for our projects, ensuring that our dependencies are managed neatly, without conflicts.\n# Create the virtual environment\nconda create --name portfolio-geek python=3.12 jupyterlab -y\n\n# Activate the environment\nconda activate portfolio-geek\n\npip install matplotlib"
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#step-4-building-a-simple-matplotlib-chart-in-visual-studio",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-windows.html#step-4-building-a-simple-matplotlib-chart-in-visual-studio",
    "title": "1-b- Setting up a Python Development Workstation (Windows)",
    "section": "Step 4: Building a Simple Matplotlib Chart in Visual Studio",
    "text": "Step 4: Building a Simple Matplotlib Chart in Visual Studio\nWe need to start somewhere! Let’s create a Notebook file (extension .ipynb) within Visual Studio and let’s type the following code.\n\n\nCode\n# Ensure you're in the 'portfolio-geek' environment\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\n# Plotting\nplt.plot(x, y)\nplt.title(\"Simple Sine Wave Plot\")\nplt.xlabel(\"X axis\")\nplt.ylabel(\"Y axis\")\nplt.show()\n\n\n\n\n\n\n\n\n\nEt Voila! The first chart in our journey to Python coding.\n\nRecap and Conclusion\nCongratulations! You’ve set up a robust coding environment for your journey into quantitative finance and data analysis. Today, we’ve installed essential tools with Chocolatey, created an isolated workspace with Conda, and dipped our toes into the world of data visualization with Matplotlib.\nWhy is this important? This setup not only equips you with the technical skills needed in the field but also instills confidence to explore complex financial models and datasets.\nAs we progress, remember that the journey is as rewarding as the destination. Keep experimenting, and don’t hesitate to dive deeper into each tool and library we discussed.\n\n\nFurther Reading and Resources\n\nBooks:\n\n“Python for Finance” by Yves Hilpisch\n“Python for Data Analysis” by Wes McKinney\n\nWebsites:\n\nOfficial Python Documentation\nMatplotlib Tutorials\n\nAwesome Python GitHub Repositories:\n\nAwesome Quant\nQuantLib\n\n\nThis structure offers a blend of instructional content and hands-on coding, making it accessible for beginners while providing enough depth for more experienced learners. The tone is kept light and encouraging, aiming to demystify the complexities of setting up a quantitative finance coding environment."
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#rendement-moyen",
    "href": "posts/10-formules-importantes-finance-marche.html#rendement-moyen",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "1. Rendement moyen",
    "text": "1. Rendement moyen\n\nUsage\nLe rendement moyen est utilisé pour estimer le rendement d’un actif financier sur une période donnée.\n\n\nContexte\nLe rendement moyen est souvent utilisé pour comparer les performances de différents actifs financiers ou pour évaluer l’efficacité d’un portefeuille d’investissement.\n\n\nFormule\n\\(\\mu = \\frac{1}{n}\\sum_{i=1}^{n}(R_i)\\)\n\n\nCode\nimport yfinance as yf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nticker = 'AAPL'\ndata = yf.download(ticker, start='2020-01-01', end='2021-01-01')['Adj Close']\nreturns = data.pct_change().dropna()\nmean_return = np.mean(returns)\n\nplt.plot(returns)\nplt.axhline(y=mean_return, color='r', linestyle='--', label=f'Mean Return: {mean_return:.4f}')\nplt.xlabel('Date')\nplt.ylabel('Returns')\nplt.legend()\nplt.show()\n\n\n[*********************100%***********************]  1 of 1 completed"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#volatilité",
    "href": "posts/10-formules-importantes-finance-marche.html#volatilité",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "2. Volatilité",
    "text": "2. Volatilité\n\nUsage\nLa volatilité est utilisée pour mesurer le risque associé à un actif financier en estimant l’écart-type de ses rendements.\n\n\nContexte\nUne volatilité élevée indique un actif plus risqué, tandis qu’une volatilité faible indique un actif moins risqué. La volatilité est souvent utilisée pour évaluer les fluctuations de prix et le risque de marché.\n\n\nFormule\n\\(\\sigma = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(R_i - \\mu)^2}\\)\n\n\nCode\nvolatility = np.std(returns, ddof=1)\n\nplt.plot(returns)\nplt.axhline(y=0, color='black', linestyle='-')\nplt.axhline(y=volatility, color='r', linestyle='--', label=f'Volatility: {volatility:.4f}')\nplt.axhline(y=-volatility, color='r', linestyle='--')\nplt.xlabel('Date')\nplt.ylabel('Returns')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#ratio-de-sharpe",
    "href": "posts/10-formules-importantes-finance-marche.html#ratio-de-sharpe",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "3. Ratio de Sharpe",
    "text": "3. Ratio de Sharpe\n\nUsage\nLe ratio de Sharpe est utilisé pour évaluer la performance ajustée au risque d’un actif financier ou d’un portefeuille d’investissement.\n\n\nContexte\nUn ratio de Sharpe élevé indique une meilleure performance ajustée au risque, tandis qu’un ratio de Sharpe faible indique une moins bonne performance. Le ratio de Sharpe est souvent utilisé pour comparer les performances de différents actifs ou portefeuilles.\n\n\nFormule\n\\(S = \\frac{\\mu - r_f}{\\sigma}\\)\n\n\nCode\nrisk_free_rate = 0.02  # Assuming a 2% annual risk-free rate\nsharpe_ratio = (mean_return - risk_free_rate) /volatility\n\nplt.plot(returns)\nplt.axhline(y=0, color='black', linestyle='-')\nplt.axhline(y=mean_return, color='g', linestyle='--', label=f'Mean Return: {mean_return:.4f}')\nplt.axhline(y=volatility, color='r', linestyle='--', label=f'Volatility: {volatility:.4f}')\nplt.axhline(y=-volatility, color='r', linestyle='--')\nplt.xlabel('Date')\nplt.ylabel('Returns')\nplt.legend()\nplt.show()\n\nprint(f'Sharpe Ratio: {sharpe_ratio:.4f}')\n\n\n\n\n\n\n\n\n\nSharpe Ratio: -0.5871"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#bêta",
    "href": "posts/10-formules-importantes-finance-marche.html#bêta",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "4. Bêta",
    "text": "4. Bêta\n\nUsage\nLa bêta est utilisée pour mesurer la sensibilité d’un actif financier par rapport aux mouvements du marché.\n\n\nContexte\nUn bêta supérieur à 1 indique un actif plus sensible aux mouvements du marché, tandis qu’un bêta inférieur à 1 indique un actif moins sensible. La bêta est souvent utilisée pour évaluer le risque systématique d’un actif ou d’un portefeuille d’investissement.\n\n\nFormule\n\\(\\beta = \\frac{\\mathrm{Cov}(R_p, R_m)}{\\mathrm{Var}(R_m)}\\)\n\n\nCode\nmarket_ticker = '^GSPC'\nmarket_data = yf.download(market_ticker, start='2020-01-01', end='2021-01-01')['Adj Close']\nmarket_returns = market_data.pct_change().dropna()\n\ncov_matrix = np.cov(returns, market_returns)\nbeta = cov_matrix[0][1] / cov_matrix[1][1]\n\nprint(f'Beta: {beta:.4f}')\n\n\n[*********************100%***********************]  1 of 1 completed\nBeta: 1.1225"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#alpha-de-jensen",
    "href": "posts/10-formules-importantes-finance-marche.html#alpha-de-jensen",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "5. Alpha de Jensen",
    "text": "5. Alpha de Jensen\n\nUsage\nL’alpha de Jensen est utilisé pour évaluer la performance d’un actif financier ou d’un portefeuille d’investissement par rapport à un indice de marché, en tenant compte du risque.\n\n\nContexte\nUn alpha de Jensen positif indique une surperformance par rapport à l’indice de marché, tandis qu’un alpha de Jensen négatif indique une sous-performance. L’alpha de Jensen est souvent utilisé pour évaluer la performance d’un gestionnaire de portefeuille.\n\n\nFormule\n\\(\\alpha = R_p - (R_f + \\beta (R_m - R_f))\\)\n\n\nCode\nalpha = mean_return - (risk_free_rate + beta * (np.mean(market_returns) - risk_free_rate))\n\nprint(f'Alpha de Jensen: {alpha:.4f}')\n\n\nAlpha de Jensen: 0.0043"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#duration-de-macaulay",
    "href": "posts/10-formules-importantes-finance-marche.html#duration-de-macaulay",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "6. Duration de Macaulay",
    "text": "6. Duration de Macaulay\n\nUsage\nLa duration de Macaulay est utilisée pour mesurer la sensibilité d’un titre à taux fixe, tel qu’une obligation, aux variations des taux d’intérêt.\n\n\nContexte\nUne duration de Macaulay élevée indique un titre plus sensible aux variations des taux d’intérêt, tandis qu’une duration de Macaulay faible indique un titre moins sensible. La duration de Macaulay est souvent utilisée pour évaluer le risque de taux d’intérêt et la stratégie de gestion d’un portefeuille d’obligations.\n\n\nFormule\n\\(D = \\frac{\\sum_{t=1}^{n} t \\times CF_t}{\\sum_{t=1}^{n} CF_t}\\)\n(Note: Cette formule est simplifiée et ne prend pas en compte la valeuractualisée des flux de trésorerie. Pour une version plus précise, consultez la formule complète de la duration de Macaulay.)\n\n\nCode\ncash_flows = np.array([10, 10, 110])  # Assuming a bond with 2 annual coupon payments of 10 and a face value of 100\ntime_periods = np.arange(1, len(cash_flows) + 1)\nmacaulay_duration = np.sum(time_periods * cash_flows) / np.sum(cash_flows)\n\nprint(f'Duration de Macaulay: {macaulay_duration:.2f}')\n\n\nDuration de Macaulay: 2.77"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#convexité",
    "href": "posts/10-formules-importantes-finance-marche.html#convexité",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "7. Convexité",
    "text": "7. Convexité\n\nUsage\nLa convexité est utilisée pour mesurer la sensibilité d’un titre à taux fixe, tel qu’une obligation, aux variations des taux d’intérêt, en tenant compte de la courbure de la relation prix-taux d’intérêt.\n\n\nContexte\nUne convexité élevée indique une plus grande sensibilité aux variations des taux d’intérêt, tandis qu’une convexité faible indique une moindre sensibilité. La convexité est souvent utilisée pour évaluer le risque de taux d’intérêt et la stratégie de gestion d’un portefeuille d’obligations.\n\n\nFormule\n\\(C = \\frac{\\sum_{t=1}^{n} t(t+1) \\times CF_t}{(1+y)^t \\times \\sum_{t=1}^{n} CF_t}\\)\n(Note: Cette formule est simplifiée et ne prend pas en compte la valeur actualisée des flux de trésorerie. Pour une version plus précise, consultez la formule complète de la convexité.)\n\n\nCode\ny = 0.03  # Assuming a 3% yield\nconvexity = np.sum(time_periods * (time_periods + 1) * cash_flows) / ((1 + y) ** time_periods * np.sum(cash_flows))\n\n#print(f'Convexité: {convexity:.2f}')"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#valeur-à-risque-var",
    "href": "posts/10-formules-importantes-finance-marche.html#valeur-à-risque-var",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "8. Valeur à Risque (VaR)",
    "text": "8. Valeur à Risque (VaR)\n\nUsage\nLa valeur à risque (VaR) est utilisée pour estimer la perte maximale potentielle d’un portefeuille d’investissement sur une période donnée et à un niveau de confiance donné.\n\n\nContexte\nLa VaR est souvent utilisée pour évaluer le risque de marché et la gestion des risques d’un portefeuille d’investissement.\n\n\nFormule\n\\(VaR = \\mu - z \\times \\sigma\\)\n\n\nCode\nconfidence_level = 0.95\nz = -np.percentile(returns, 100 - (confidence_level * 100))\nvar = -mean_return - z * volatility\n\nprint(f'Valeur à Risque (VaR) à {confidence_level * 100}%: {var:.4f}')\n\n\nValeur à Risque (VaR) à 95.0%: -0.0040"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#value-at-risk-conditionnel-cvar",
    "href": "posts/10-formules-importantes-finance-marche.html#value-at-risk-conditionnel-cvar",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "9. Value at Risk Conditionnel (CVaR)",
    "text": "9. Value at Risk Conditionnel (CVaR)\n\nUsage\nLe CVaR est utilisé pour estimer la perte moyenne potentielle d’un portefeuille d’investissement au-delà de la VaR, sur une période donnée et à un niveau de confiance donné.\n\n\nContexte\nLe CVaR est souvent utilisé pour évaluer le risque de marché et la gestion des risques d’un portefeuille d’investissement, en se concentrant sur les pertes extrêmes.\n\n\nFormule\n\\(CVaR = \\frac{1}{(1 - \\alpha)}\\int_{-\\infty}^{-VaR} xf(x)dx\\)\n\n\nCode\ncvar = -np.mean(returns[returns &lt; -var])\n\nprint(f'Value at Risk Conditionnel (CVaR) à {confidence_level * 100}%: {cvar:.4f}')\n\n\nValue at Risk Conditionnel (CVaR) à 95.0%: 0.0168"
  },
  {
    "objectID": "posts/10-formules-importantes-finance-marche.html#corrélation",
    "href": "posts/10-formules-importantes-finance-marche.html#corrélation",
    "title": "Les 10 formules les plus utilisées en finance de marché",
    "section": "10. Corrélation",
    "text": "10. Corrélation\n\nUsage\nLa corrélation est utilisée pour mesurer la relation entre les rendements de deux actifs financiers.\n\n\nContexte\nUne corrélation positive indique que les rendements de deux actifs évoluent généralement dans la même direction, tandis qu’une corrélation négative indique qu’ils évoluent généralement dans des directions opposées. La corrélation est souvent utilisée pour évaluer la diversification d’un portefeuille d’investissement.\n\n\nFormule\n\\(\\rho = \\frac{\\mathrm{Cov}(R_i, R_j)}{\\sigma_i \\sigma_j}\\)\n\n\nCode\nticker_2 = 'MSFT'\ndata_2 = yf.download(ticker_2, start='2020-01-01', end='2021-01-01')['Adj Close']\nreturns_2 = data_2.pct_change().dropna()\n\ncorrelation_matrix = np.corrcoef(returns, returns_2)\ncorrelation = correlation_matrix[0][1]\n\nprint(f'Corrélation entre {ticker} et {ticker_2}: {correlation:.4f}')\n\n\n[*********************100%***********************]  1 of 1 completed\nCorrélation entre AAPL et MSFT: 0.8393\n\n\nCes 10 formules sont essentielles pour comprendre et analyser les actifs financiers et les portefeuilles d’investissement en finance de marché. En utilisant ces formules et les outils Python tels que yfinance et matplotlib, vous pouvez facilement récupérer des données de marché et visualiser les résultats de vos analyses."
  },
  {
    "objectID": "posts/data-and-apis/exploring-worldbank-api.html",
    "href": "posts/data-and-apis/exploring-worldbank-api.html",
    "title": "Exploring the Worldbank API (WBGAPI)",
    "section": "",
    "text": "Code\nimport wbgapi as wb\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n\nCode\nincomes = wb.income.list()\ndata = wb.data.fetch('SP.POP.TOTL', 'USA', 2000, 2020)\n\n\n\n\nCode\ndata\n\n\n&lt;generator object fetch at 0x10ab110b0&gt;"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html",
    "title": "Estimate Financial Risk",
    "section": "",
    "text": "## Introduction In today’s session, we will\nCode\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n#import pandas_datareader as web_reader\nfrom pandas_datareader import data as pdr\nimport yfinance as yf\n\n\nimport matplotx\nimport matplotlib.dates as mdates\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nimport math\nimport seaborn as sns\n\ntickers = ['SPY']\n\nstart_date = '2018-09-14'\nend_date = '2022-09-14'\ntickers = ['SPY', 'AGG']\n#yf.pdr_override(tickers)\ndf = yf.download(tickers,  start=start_date, end=end_date)\ndata = df.Close.SPY.resample(\"B\").last().fillna(method=\"bfill\")\ndata_agg = df.Close.AGG.resample(\"B\").last().fillna(method=\"bfill\")\n\n\n[                       0%                       ][*********************100%***********************]  2 of 2 completed"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-close-price",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-close-price",
    "title": "Estimate Financial Risk",
    "section": "Plot Historical Close Price",
    "text": "Plot Historical Close Price\n\n\nCode\ntpl_path = \"https://github.com/vdenoise/templates/raw/master\"\nmpl_tpl_path = f\"{tpl_path}/matplotlib\"\n\nplt.style.use(f\"{mpl_tpl_path}/dracula_slide.mplstyle\")\ndata.resample(\"W\").last().plot(figsize=(4,6));\nplt.ylabel(\"Wealth Curve\")  \nmatplotx.line_labels()  \n\nplt.savefig(\"output/wealth_curve_spy.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-returns",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-returns",
    "title": "Estimate Financial Risk",
    "section": "Plot Historical Returns",
    "text": "Plot Historical Returns\n\n\nCode\nplt.figure(figsize=(8, 6))\ndata_bar = data.resample(\"W\").last().pct_change().multiply(100)\nindex = data_bar.index\nindex = [pd.to_datetime(date, format='%Y-%m-%d').date() for date in index]\ndata_bar.index = index\nax = data_bar.plot.bar()\nplt.ylabel(\"Weekly Return (%)\")\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\nplt.gcf().autofmt_xdate()\nplt.savefig(\"output/weekly_returns_spy.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#sorted-weekly-returns",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#sorted-weekly-returns",
    "title": "Estimate Financial Risk",
    "section": "Sorted Weekly Returns",
    "text": "Sorted Weekly Returns\n\n\nCode\nsorted_returns = data.resample(\"W\").last().pct_change().multiply(100).sort_values()\nsorted_returns.plot(figsize=(8, 6));\nplt.savefig(\"output/sorted_weekly_returns_spy.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#return-distribution",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#return-distribution",
    "title": "Estimate Financial Risk",
    "section": "Return Distribution",
    "text": "Return Distribution\n\n\nCode\ndata_bar.hist(bins=100, figsize=(8,6));\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(8, 6))\nax = sns.kdeplot(data_bar)\nmean = data_bar.mean()\nstd = data_bar.std()\nN = 10\nfor i in [1, 2, 3]:\n    x1 = np.linspace(mean - i*std, mean - (i - 1)*std, N)\n    x2 = np.linspace(mean - (i - 1)*std, mean + (i - 1)*std, N)\n    x3 = np.linspace(mean + (i - 1)*std, mean + i*std, N)\n    x = np.concatenate((x1, x2, x3))\n    x = np.where((mean - (i - 1)*std &lt; x) & (x &lt; mean + (i - 1)*std), np.nan, x)\n    y = norm.pdf(x, mean, std)\n    ax.fill_between(x, y, alpha=0.5)\n\nplt.xlabel(\"SPY Weekly Returns (in %, US Dollar)\")\nplt.ylabel(\"Probability Density Function\")\n#plt.xticks(ticks=range(0, 10))\nplt.grid()\n\nplt.show()"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#historical-volatility",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#historical-volatility",
    "title": "Estimate Financial Risk",
    "section": "Historical Volatility",
    "text": "Historical Volatility\n\n\nCode\nplt.figure(figsize=(8, 6))\nplt.savefig(\"output/wealth_curve_spy.png\" );\ndata.resample(\"W\").last().pct_change().rolling(52).std().multiply(math.sqrt(52)).plot(secondary_y=True)\nmatplotx.line_labels() \nplt.savefig(\"output/wealth_curve_spy_with_vol.png\" );\n\n\n\n\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(8, 6))\ndata.resample(\"W\").last().pct_change().rolling(52).std().multiply(math.sqrt(52)).plot(secondary_y=False)\nmatplotx.line_labels()\nplt.savefig(\"output/vol_spy.png\" );\ndata_agg.resample(\"W\").last().pct_change().rolling(52).std().multiply(math.sqrt(52)).plot(secondary_y=False)\nmatplotx.line_labels()\nplt.savefig(\"output/vol_spy_with_agg.png\" );"
  },
  {
    "objectID": "portfolio_construction.html",
    "href": "portfolio_construction.html",
    "title": "Portfolio Construction",
    "section": "",
    "text": "Estimating risks and returns is probably the most important - and the most difficult - topic in quantitative finance. There are plenty of approaches to tackle it.\nBelow is a series of articles delving into various approaches and techniques to analyse time series and estimating risk and returns. This list will be augmented over time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPortfolio optimisation with Python\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/data-and-apis/test_wb.html",
    "href": "posts/data-and-apis/test_wb.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "posts/data-and-apis/test_wb.html#installation",
    "href": "posts/data-and-apis/test_wb.html#installation",
    "title": "",
    "section": "Installation",
    "text": "Installation\nTo start, ensure that you have the WBGAPI library installed. If not, you can do so using pip:\npip install wbgapi"
  },
  {
    "objectID": "posts/data-and-apis/test_wb.html#setting-the-stage",
    "href": "posts/data-and-apis/test_wb.html#setting-the-stage",
    "title": "",
    "section": "Setting the Stage",
    "text": "Setting the Stage\nFirstly, we need to import the necessary libraries. WBGAPI will be used to gather data, pandas for data manipulation, and matplotlib for visualisation.\nimport wbgapi as wb\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/data-and-apis/test_wb.html#use-case-1-gdp-evolution-of-emerging-vs-developed-markets",
    "href": "posts/data-and-apis/test_wb.html#use-case-1-gdp-evolution-of-emerging-vs-developed-markets",
    "title": "",
    "section": "Use Case 1: GDP Evolution of Emerging vs Developed Markets",
    "text": "Use Case 1: GDP Evolution of Emerging vs Developed Markets\nGross Domestic Product (GDP) serves as a broad measure for a country’s overall economic activity. It represents the monetary value of all finished goods and services produced within a country’s borders in a specific time period.\nHere is how we can fetch the data:\n# Get income level codes for \"High income\" (developed markets) and \"Lower middle income\" and \"Upper middle income\" (emerging markets)\nincome_levels = wb.income.list().set_index('id')['name']\ndeveloped = [code for code, name in income_levels.items() if 'High income' in name]\nemerging = [code for code, name in income_levels.items() if 'middle income' in name]\n\n# Fetch GDP data (NY.GDP.MKTP.CD) for the last 30 years\nyears = list(range(1994, 2024))\ngdp_developed = wb.data.DataFrame('NY.GDP.MKTP.CD', country=developed, time=years).mean(axis=1)\ngdp_emerging = wb.data.DataFrame('NY.GDP.MKTP.CD', country=emerging, time=years).mean(axis=1)\n\n# Create a DataFrame\ndf_gdp = pd.DataFrame({'Developed Markets': gdp_developed, 'Emerging Markets': gdp_emerging})\nWe can now visualise the data:\ndf_gdp.plot(kind='line')\nplt.title('GDP Evolution: Developed vs Emerging Markets (1994-2024)')\nplt.xlabel('Year')\nplt.ylabel('GDP (Current US$)')\nplt.show()"
  },
  {
    "objectID": "posts/data-and-apis/test_wb.html#use-case-2-gdp-per-capita-evolution-for-selected-countries",
    "href": "posts/data-and-apis/test_wb.html#use-case-2-gdp-per-capita-evolution-for-selected-countries",
    "title": "",
    "section": "Use Case 2: GDP per Capita Evolution for Selected Countries",
    "text": "Use Case 2: GDP per Capita Evolution for Selected Countries\nGDP per capita is a measure of the total output of a country that takes the GDP and divides it by the number of people in that country. The countries we will focus on are the USA, France, Germany, Japan, China, and India.\nFetching the data is straightforward:\n# Specify countries and fetch data for GDP per capita (NY.GDP.PCAP.CD)\ncountries = ['USA', 'FRA', 'DEU', 'JPN', 'CHN', 'IND']\ndf_gdp_pc = wb.data.DataFrame('NY.GDP.PCAP.CD', country=countries, time=years)\nAnd let’s visualise this:\ndf_gdp_pc.plot(kind='line')\nplt.title('GDP per Capita\n\n Evolution: USA, France, Germany, Japan, China, India (1994-2024)')\nplt.xlabel('Year')\nplt.ylabel('GDP per Capita (Current US$)')\nplt.show()"
  },
  {
    "objectID": "posts/data-and-apis/test_wb.html#conclusion",
    "href": "posts/data-and-apis/test_wb.html#conclusion",
    "title": "",
    "section": "Conclusion",
    "text": "Conclusion\nWorld Bank data provides invaluable insight into the world’s economic trends, and the WBGAPI library is an incredibly useful tool for extracting this data in an easy and efficient manner. It enables researchers, analysts, and policymakers to gauge economic performance, identify trends, and make evidence-based decisions.\nWhether you are a student, economist, or data enthusiast, the potential of such data is boundless. By coupling World Bank data with Python’s analytical and visualisation capabilities, you can make economic trends come alive, allowing for more profound, insightful analysis and decision-making."
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#introduction",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#introduction",
    "title": "Portfolio optimisation with Python",
    "section": "Introduction",
    "text": "Introduction\nHarry Markowitz is one of the (if not “the”) fathers of modern portfolio construction and his seminal paper Portfolio Selection 1 has driven an entire research stream.\nThe intuition behind this paper is that one can combine the information gathered on expected returns, risks and diversification of various assets or asset classes with a view to optimise the risk-return profile of a given portfolio.\nIn practice, we typically find a limited stability of the portfolios generated using this approach, especially due the high sensitivity of the portfolio to the expected returns; nonetheless, the insights it provides are very useful and it’s a perfect start to see the impact of risk and diversification.\nFor this article, we will mostly rely on a fantastic Python library, PyPortfolioOpt 2 which will do the optimisation heavy lifting for us."
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#setup",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#setup",
    "title": "Portfolio optimisation with Python",
    "section": "Setup",
    "text": "Setup\n\nLoading Libraries\nThe main library to load here is indeed PyPortfolioOpt, and we will rely extensively on it in this article.\nWe need the following tools as well:\n\nPandas: load, filter, sort and pretty much all data wrangling operations;\nNumpy: provides most matrix and advanced numerical operations; this library is the calculation backbone for pandas;\nMatplotlib: the de facto reference library to draw scientific charts;\nyfinance: a very handy library to access many different online databases, including Yahoo Finance.\n\n\n\nCode\n#collapse-hide\nimport numpy as np \nimport pandas_datareader.data as web_reader\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport yfinance as yf\n\nfrom pypfopt.efficient_frontier import EfficientFrontier\nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns\n\n\n\n\nMisc Parameters\nIn the code below, we set some variables to adjust the jupyter loo\n\n\nCode\n#collapse-hide\n# Note that this change the decimals places inside Jupyter, but not on the website\npd.options.display.float_format = '{:,.1f}'.format"
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#defining-our-investable-universe",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#defining-our-investable-universe",
    "title": "Portfolio optimisation with Python",
    "section": "Defining our Investable Universe",
    "text": "Defining our Investable Universe\nFirst and foremost, we need to define our Investable Universe i.e. the set of asset classes that we will allow in our portfolio.\nMany investors would typically think about single stocks, but on my side, I am typically looking I am looking here a Long Term Investing, and I would be keen to\nSpeaking about asset classes, we need some ETFs to analyse!\n\n“Important: Please bear in mind this article if purely for pedagogical purpose and should by no mean be understood as a recommendation or advice. Investing brings risk and in particular risk of loss of capital. I have no intention to recommend anything! I will follow among others this recent article in US News{% fn 7%} and ETF.com{% fn 8%} as sources of inspiration to identify relevant ETFs.”\n\n\nEquity\nLet’s start with various Equity sub-asset classes:\n\nIVV: iShares Core S&P 500 ETF representing US Equity Large Cap\nSCHA: Schwab U.S. Small-Cap ETF representing US Equity Small Cap\nIJH: iShares Core S&P Mid-Cap ETF representing US Equity Mid Cap\nSCHD: Schwab U.S. Dividend Equity ETF representing US Equity Dividend (ie US stocks which are deemed to pay higher dividends)\nVTI: Vanguard Total Stock Market ETF representing US Equity, with all market cap included\nVXUS: Vanguard Total International Stock ETF representing World ex-US equities\nEEM: iShares MSCI Emerging Markets ETF representing the Emerging Market Equities\n\n\n\nFixed Income\nLet’s add Fixed Income, which would typically aim to reduce the overall portfolio’s volatility:\n\nAGG: iShares Core U.S. Aggregate Bond ETFrepresenting the entire US Bond market\nGOVT: iShares U.S. Treasury Bond ETF representing the performance of US Government Bonds\nVCLT: Vanguard Long-Term Corporate Bond ETF representing the Investment Grade USD denominated bonds.\n\n\n\nAlternative Assets\nLet’s add 2 additional asset classes, Gold and Commodities:\n\nGLD: SPDR Gold Trust representing the price of **Gold\nPDBC: Invesco Optimum Yield Diversified Commodity Strategy No K-1 ETF** which will represent the performance of the Broad Commodities asset class\n\nEverything in the above is denominated in US Dollars, this will make our life easier in what follows, ie we will not need any currency conversion, which is always a bit painful in the process."
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#parameters-and-data-gathering",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#parameters-and-data-gathering",
    "title": "Portfolio optimisation with Python",
    "section": "Parameters and data gathering",
    "text": "Parameters and data gathering\nI recommend you to read this article about data gathering.\nLike we did in this article, we will utilise yfinance to get historical time series. As mentioned above, we will look at the performance of ETFs, which we will consider as as relevant proxies for their respective asset classes.\nYou can of course utilise whatever asset class you want, and take single stocks, funds as historical data points. On my side, I am quite familiar with indices ETFs, and I will go with the selection above.\nLast but not least, we need to define the start_date and end_date for gathering the historical time series. For this study, we will gather 7 years of data.\n\n\nCode\n#collapse-hide\n\nstart_date = '2018-03-01'\nend_date = '2023-03-01'\n\n# Define Investable Universe\ninvestable_universe_tickers = ['IVV', 'SCHA', 'IJH', 'SCHD', 'VTI', 'VXUS', 'EEM', 'VCLT', 'AGG', 'GOVT','PDBC','GLD']\n\n# Get Historical Data\ndf = yf.download(investable_universe_tickers, start=start_date, end=end_date, progress=False)\ndf = df['Adj Close']\n\n# This is required to round the blog's table into 2 decimals, Jupyter's formatting does not apply on the published website\ndf = df.round(decimals=1)\n\n\n\nData gathering: results\nThe request above delivered a pandas data_frame, and here is a snapshot of the last 5 rows:\n\n\nCode\n#collapse-hide\ndf.tail(3)\n\n\n\n\n\n\n\n\n\n\nAGG\nEEM\nGLD\nGOVT\nIJH\nIVV\nPDBC\nSCHA\nSCHD\nVCLT\nVTI\nVXUS\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2023-02-24\n94.0\n37.3\n168.4\n22.1\n255.3\n391.8\n13.6\n43.1\n72.2\n72.9\n196.4\n51.9\n\n\n2023-02-27\n94.2\n37.5\n169.0\n22.1\n255.9\n393.2\n13.6\n43.2\n72.2\n72.7\n197.1\n52.4\n\n\n2023-02-28\n94.2\n37.2\n169.8\n22.1\n255.3\n391.7\n13.7\n43.2\n71.9\n72.8\n196.4\n52.0\n\n\n\n\n\n\n\n\n\n\nNormalisation\nA table like the above is not very useful: in the absence a of particle knowledge of the ETFs’ values, we have no way of knowing if a value is “high” or “low”, hence apart from telling us that the value is a number we have now way to let’s try to make this table a bit more insightful.\nThe request above delivered a data_frame, and here is a snapshot of the last 5 rows:\n\n\nCode\n#collapse-hide\n# Same table, but this time, normalised\n(df/df.iloc[0, ]*100).round(decimals=1).tail(3)\n\n\n\n\n\n\n\n\n\n\nAGG\nEEM\nGLD\nGOVT\nIJH\nIVV\nPDBC\nSCHA\nSCHD\nVCLT\nVTI\nVXUS\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2023-02-24\n102.5\n89.0\n134.7\n100.9\n150.4\n159.4\n146.2\n136.4\n174.4\n102.0\n156.2\n109.3\n\n\n2023-02-27\n102.7\n89.5\n135.2\n100.9\n150.8\n160.0\n146.2\n136.7\n174.4\n101.7\n156.8\n110.3\n\n\n2023-02-28\n102.7\n88.8\n135.8\n100.9\n150.4\n159.4\n147.3\n136.7\n173.7\n101.8\n156.2\n109.5\n\n\n\n\n\n\n\n\nThis is much better.\nNow we can at least see that: - US Equities (e.g. IVV) had a fantastic ride since 2015; - Government bonds (e.g. GOVT) under-performed; - Commodities (PDBC) and Gold (GLD) had several rough years as well, with recent massive pick-up in the current geopolitical context.\n\n\nVisualise asset classes’ returns\nBeing able to sanity check the data is very important, and it’s often more efficient with a quick chart.\n\n\nCode\n#collapse-hide\n\n# Normalise to 100\nnormalised_data = (df/df.iloc[0, ]*100)\n\n# A bit of data wrangling\ntransposed_data = normalised_data.tail(1).reset_index().transpose()\ntransposed_data = transposed_data.iloc[1:len(transposed_data)]\ntransposed_data = transposed_data.rename(columns={0: \"Last Value\"})\n\n# We want a bar chart sorted by decreaseing values\ntransposed_data = transposed_data.sort_values(by=\"Last Value\", ascending=False)\n\n# Theming Seaborn results\nsns.set_theme()\n\n# Draw\ntransposed_data.plot.bar(figsize=(10, 6))\npass\n\n\n\n\n\n\n\n\n\n\n\nDraw the wealth curve\nThe table above is useful, but when it comes to grasping and long term risks and returns, a chart is worth a thousand words.\nA very common issue when charting multiple time series is the very different stock levels, and this can make the chart hard to read.\nThis is why we will once again normalise the data.\n\n\nCode\n#collapse-hide\n\n# Theming Seaborn results\nsns.set_theme()\n\n# Plot the time series\nplt.figure(figsize=(12,6))\n\n# Legends and Axis titles\np = sns.lineplot(data=normalised_data)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#estimate-risk-and-return",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#estimate-risk-and-return",
    "title": "Portfolio optimisation with Python",
    "section": "Estimate risk and return",
    "text": "Estimate risk and return\nIn Markowitz 1952, the optimal portfolio is obtained as a function of expected returns and expected risks of the portfolio. This takes a strong assumption that we have a “crystal ball”, or at least access to a predictive model, which at this stage is well beyond this article.\nFor this first example, we will rely on historical parameters estimation, which precisely means that we expect the past to be a good prediction of what might happen in the future.\n\nVolatility\nThere are many ways to estimate the volatility, and I will only cover the simplest approach.\nWe have access to daily close prices of the ETFs, hence we could look at the standard deviation of daily returns. In theory this would utilise most of the data we have access to, which is a good thing. In practice, and especially when looking at asset classes which can be observed with an 8 to 12 hours time difference which might lead the “sample volatility” to become inconsistent between 2 asset classes. This is even more important for estimating the correlation.\nPractitioners often use weekly returns to alleviate this issue, and we will do the same here, and as such calculate the returns using a resampled time series. To calculate the annualized volatility requires an additional factor in this case the square root of 52. Why this?\nVolatility is essential to option traders, and when pricing options, practitioners often model asset prices as Wiener processes(number of weeks in a year) 3. The variance of a Wiener process is proportional to the time, and the volatility is the square root of the the variance, which gives us that to convert standard deviation of weekly returns into an annualized figure, we need to multiply our results by the square root of the number of weeks in a year.\n\n\nCode\nweekly_returns = df.resample(\"W\").last().pct_change()\n((weekly_returns.std()*math.sqrt(52)*100).sort_values()).plot.bar();\n\n\n\n\n\n\n\n\n\nAs one could have guessed, on the left of the chart above, we can find the low volatility asset classes (e.g. Government Bonds, Investment Grade Bonds), whereas on the right we have high volatility asset classes (Mid Cap and Small Cap Equities)."
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#correlation",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#correlation",
    "title": "Portfolio optimisation with Python",
    "section": "Correlation",
    "text": "Correlation\n\n\nCode\nsns.heatmap(weekly_returns.corr());\n\n\n\n\n\n\n\n\n\n\n\nCode\n#collapse-hide\nfrom pypfopt import risk_models\nfrom pypfopt import plotting\n\n# Calculate expected returns and sample covariance\nmu = expected_returns.mean_historical_return(df)\nsample_cov = risk_models.sample_cov(df, frequency=252)\n\nS = risk_models.CovarianceShrinkage(df).ledoit_wolf()"
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#the-main-results-efficient-frontier-maximum-sharpe-portfolio",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#the-main-results-efficient-frontier-maximum-sharpe-portfolio",
    "title": "Portfolio optimisation with Python",
    "section": "The main results: Efficient Frontier & Maximum Sharpe Portfolio",
    "text": "The main results: Efficient Frontier & Maximum Sharpe Portfolio\n\nCalculate and draw the efficient frontier\nWith expected returns and risk estimated, we are ready to utilise PyPortfolioOpt’s optimiser to draw the efficient frontier.\nThe idea behind the efficient frontier is relatively simple: - For each level of investor’s risk, there is an optimal portfolio which is expected to deliver the highest level of return; or conversely - For each level of investor’s return, there is an optimal portfolio which is expected to deliver the lowest level of return.\n\n\nCode\n#collapse-hide\nef = EfficientFrontier(mu, sample_cov)\n\n# We create 2 efficient frontiers\nfig, ax = plt.subplots()\nplotting.plot_efficient_frontier(ef, ax=ax, show_assets=True)\nax.set_title(\"Asset Classes & Efficient Frontier\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAdd the Maximum Sharpe portfolio\n\n\nCode\n#collapse-hide\n\n# Find and plot the tangency portfolio\nfig2, ax = plt.subplots()\nef2 = EfficientFrontier(mu, S) \nplotting.plot_efficient_frontier(ef2, ax=ax, show_assets=True)\n\nef3 = EfficientFrontier(mu, S) \n\nef3.max_sharpe()\nret_tangent, std_tangent, _ = ef3.portfolio_performance()\nax.scatter(std_tangent, ret_tangent, marker=\"*\", s=100, c=\"r\", label=\"Max Sharpe\")\nax.set_title(\"Asset Classes, Efficient Frontier & Max Sharpe portfolio\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCalculate random portfolios\n\n\nCode\n#collapse-hide\n\n# Plot random portfolios\nfig2, ax = plt.subplots()\nn_samples = 10000\nw = np.random.dirichlet(np.ones(len(mu)), n_samples)\nrets = w.dot(mu)\nstds = np.sqrt((w.T * (S @ w.T)).sum(axis=0))\nsharpes = rets / stds\nax.scatter(stds, rets, marker=\".\", c=sharpes, cmap=\"viridis_r\")\n\n# Format\nax.set_title(\"Random portfolios, based on the same asset classes\")\n#ax.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#conclusion",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#conclusion",
    "title": "Portfolio optimisation with Python",
    "section": "Conclusion",
    "text": "Conclusion\nEt voila!\nCompared to macros or Excel formulas, this is an amazing improvement, and enables us to customise everything in seconds: historical timeframe, asset classes, etc.\nTo deliver a full portfolio optimisation process in such a limited number of lines is truly awesome.\nI hope this article provided you some ideas on how to look at portfolio construction.\nHappy coding, and happy portfolio construction!"
  },
  {
    "objectID": "posts/portfolio-construction/optimise-portfolios-with-python.html#footnotes",
    "href": "posts/portfolio-construction/optimise-portfolios-with-python.html#footnotes",
    "title": "Portfolio optimisation with Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPortfolio Selection, Henri Markowitz, 1952↩︎\nPyportfolioOpt, Robert Andrew Martin, 2018↩︎\nWikipedia.com / Wiener Processes↩︎"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#introduction",
    "href": "posts/publication-workflow/visualizing-historical-data.html#introduction",
    "title": "Visualising Historical Data",
    "section": "Introduction",
    "text": "Introduction\nTo start our data analysis and portfolio construction journey, we will perform the basic - but essential - task of getting access to time series and plot them using pandas.\n\nTip: This article is written as a Jupyter Notebook. It has been published using Fastpages. The Jupyter notebook is available on GitHub and if you want to, you can run it directly using the provided Binder link displayed at the top of the article."
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#load-libraries",
    "href": "posts/publication-workflow/visualizing-historical-data.html#load-libraries",
    "title": "Visualising Historical Data",
    "section": "Load libraries",
    "text": "Load libraries\nA key benefit of Python is the sheer number of libraries we can leverage to perform a particular task. Choosing the right library might look a bit overwhelming, and one the goals of this blog is actually to provide the reader my honest view on what makes most sense to perform the usual tasks in my daily work.\nThe key module for this article is yfinance, a fantastic data gathering library that you can find here on GitHub.\n\n\nCode\n#collapse-hide\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport yfinance as yf\nimport datetime as dt\n\n# Note that this change the decimals places inside Jupyter, but not on the website\npd.options.display.float_format = '{:,.1f}'.format"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#get-historical-data",
    "href": "posts/publication-workflow/visualizing-historical-data.html#get-historical-data",
    "title": "Visualising Historical Data",
    "section": "Get historical data",
    "text": "Get historical data\nLet’s get ready, and gather some historical data for, say, 4 Exchange Traded Funds (ie “ETFs”, still commonly referred to as “trackers” in France): - SPY: S&P 500 - GLD: Gold - AGG: US Aggregate (US Bonds) - CAC.PA: CAC 40 (French Equity Index)\nYou might wonder what the first 3 letters actually correspond to? They are the usual identifier for each ETF on the markets, and are often called the tickerof the ETF.\nTo gather data, you must de facto provide one ticker for each security, but if you forgot the ticker, Google is usually your friend!\nWe will need define to find a few more parameters: - The 2 variables start_date and end_date to keep some flexibility, - The variable tickers will store our ticker list, and pass it as a parameter to Yahoo, in order to specify our query.\n\n\nCode\n#collapse-hide\n\nstart_date = '2015-01-01'\nend_date = '2022-05-14'\ntickers = ['SPY', 'GLD', 'AGG', 'CAC.PA']\ndf = yf.download(tickers,  start=start_date, end=end_date)\n\n# This ones keep the decimals to one on the website. \n# This is especially useful to print dataframes.\ndf = df.round(decimals=2)\n\n\n\n[                       0%                       ][                       0%                       ][**********************75%***********            ]  3 of 4 completed[*********************100%***********************]  4 of 4 completed"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#visual-data-check",
    "href": "posts/publication-workflow/visualizing-historical-data.html#visual-data-check",
    "title": "Visualising Historical Data",
    "section": "Visual data check",
    "text": "Visual data check\nBy default, Yahoo Finance provides us with several fields, not all of them will be useful in this introduction, and we will perform some further filtering below.\nTo quickly check the status of what we now have, note the use of the tail() function below.\nPandas tail() function\n\n\nCode\ndf.tail(3)\n\n\n\n\n\n\n\n\n\n\nAdj Close\nClose\nHigh\n...\nLow\nOpen\nVolume\n\n\n\nAGG\nCAC.PA\nGLD\nSPY\nAGG\nCAC.PA\nGLD\nSPY\nAGG\nCAC.PA\n...\nGLD\nSPY\nAGG\nCAC.PA\nGLD\nSPY\nAGG\nCAC.PA\nGLD\nSPY\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022-05-11\n98.5\n60.8\n172.8\n383.4\n102.8\n62.6\n172.8\n392.8\n102.8\n62.6\n...\n172.2\n392.0\n102.1\n61.7\n172.5\n398.1\n16,462,000.0\n45,387.0\n9,179,600.0\n142,361,000.0\n\n\n2022-05-12\n98.6\n60.2\n170.2\n383.0\n103.0\n62.0\n170.2\n392.3\n103.1\n62.3\n...\n169.9\n385.1\n102.9\n61.4\n172.1\n389.4\n9,015,300.0\n62,497.0\n11,626,800.0\n125,090,800.0\n\n\n2022-05-13\n98.2\n61.7\n168.8\n392.2\n102.5\n63.5\n168.8\n401.7\n102.8\n63.5\n...\n168.0\n395.6\n102.8\n62.4\n168.3\n396.7\n6,715,600.0\n77,603.0\n13,031,100.0\n104,174,400.0\n\n\n\n\n3 rows × 24 columns\n\n\n\n\nThe Adjusted Close field is returned by Yahoo Finance and is exactly what we are looking for.\nAdjusted Close corresponds to the time series containing what we usually call the total return, typically compounding the dividends with the price returns.\nThis reflects the total return delivered by the ETF, should the investor reinvest systematically the dividend paid by the ETF by buying more this ETF. This is probably the most useful field when we aim to assess the long term returns of an asset class.\nTo quickly check the status of what we now have, note the use of the tail() function below, which get the last n rows of the dataset. Combined with Jupyter’s power in printing data, it’s probably the fastest way to navigate and check a particular dataset.\nPandas tail() function\n\n\nCode\ndf['Adj Close'].tail(3)\n\n\n\n\n\n\n\n\n\n\nAGG\nCAC.PA\nGLD\nSPY\n\n\nDate\n\n\n\n\n\n\n\n\n2022-05-11\n98.5\n60.8\n172.8\n383.4\n\n\n2022-05-12\n98.6\n60.2\n170.2\n383.0\n\n\n2022-05-13\n98.2\n61.7\n168.8\n392.2"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#plot-the-raw-time-series-using-the-seaborn-library",
    "href": "posts/publication-workflow/visualizing-historical-data.html#plot-the-raw-time-series-using-the-seaborn-library",
    "title": "Visualising Historical Data",
    "section": "Plot the raw time series using the seaborn library",
    "text": "Plot the raw time series using the seaborn library\nTo quickly check that we got the right data, let’s visualise it.\n\n\nCode\n#collapse-hide\nimport seaborn as sns\n\n# Apply the default theme\nsns.set_style('whitegrid')\n\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=df['Adj Close'])\np.set_ylabel(\"Close Price\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#plot-the-normalised-the-time-series",
    "href": "posts/publication-workflow/visualizing-historical-data.html#plot-the-normalised-the-time-series",
    "title": "Visualising Historical Data",
    "section": "Plot the normalised the time series",
    "text": "Plot the normalised the time series\nThe chart above is useful, but the vast difference between the ETFs’ values makes it a bit hard to actually track each respective time series.\nIt would be more effective to normalise the data. It’s often referred to as “rebasing”, ie making each time series starting at 100, this will make it much easier to compare.\n\n\nCode\n#collapse-hide\n\n# Normalise the data, which here means for each column to start at 100, with subsequent price development \"scaled\" according to daily returns\nnormalised_ts = (df['Adj Close']/df['Adj Close'].iloc[0, ]*100)\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=normalised_ts)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#rolling-window-cumulated-returns",
    "href": "posts/publication-workflow/visualizing-historical-data.html#rolling-window-cumulated-returns",
    "title": "Visualising Historical Data",
    "section": "Rolling window cumulated returns",
    "text": "Rolling window cumulated returns\nIt’s often easy to get ‘seduced’ by the compelling long term returns, especially about Equities. And indeed, it was a good thing to be invested in Equities in the long run !\nBut 1y returns are usually a good way to keep track of the portfolio, and moreover to see how these returns have developed over time. With a 1y return chart, the notion of risk, ie either fast-changing returns, or - even worse - consistently negative returns, quickly becomes apparent.\n\n\nCode\n# We use pct_change() to calculate the one year return\nts_1y_returns = df['Adj Close'].pct_change(periods=252)\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=ts_1y_returns)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#smoother-returns",
    "href": "posts/publication-workflow/visualizing-historical-data.html#smoother-returns",
    "title": "Visualising Historical Data",
    "section": "Smoother returns",
    "text": "Smoother returns\nThe chart above is great, but a bit too busy for my taste. Whilst accurate, there is too much info going on, the noise might reduce our ability to spot real medium terms or breakouts.\nThis is where pandas starts to be really powerful. The rolling() function essentially captures sub-series, with a defined length (here 21 days). By chaining the results of rolling() with the mean function, ie calculating the arithmetic average, this will provide us in a one-liner with a new series. This generated dataframe contains the time series of the moving average (21 days) for each of our time series.\nWhilst this “chaining” approach might initially sound obscure, this is extremely powerful, especially when factoring in the fact that you just need to change the tickers of the ETFs in the beginning of the article to entirely update the whole analysis … your turn!\n\n\nCode\n# Normalise the data, which here means for each column to start at 100, with subsequent price development \"scaled\" according to daily returns\nts_1y_returns = df['Adj Close'].pct_change(periods=252).rolling(window=21).mean()\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=ts_1y_returns)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#conclusion",
    "href": "posts/publication-workflow/visualizing-historical-data.html#conclusion",
    "title": "Visualising Historical Data",
    "section": "Conclusion",
    "text": "Conclusion\nSo that’s it for this short intro on data gathering and visualising. In this article, we have gathered, checked, normalised and plot close prices for different ETFs.\nThe next step will be to use these function to generate some returns and risk statistics, and start exploring portfolio construction.\nSee you in the next article, and stay safe."
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#useful-related-links",
    "href": "posts/publication-workflow/visualizing-historical-data.html#useful-related-links",
    "title": "Visualising Historical Data",
    "section": "Useful Related Links",
    "text": "Useful Related Links\n{% series_list %}\nThere is no such thing as “full tutorial on something”, knowledge is everywhere. I found these tutorials pretty handy, check them out too!\n\nSeaborn Tutorial\nTutorial on F-Strings"
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#le-price-to-earnings-ratio-per",
    "href": "posts/tutorials/fr/valorisation-pe.html#le-price-to-earnings-ratio-per",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Le Price to Earnings Ratio (“PER”)",
    "text": "Le Price to Earnings Ratio (“PER”)\nLe Price to Earnings Ratio (PER) est un ratio financier utilisé pour évaluer la valorisation d’une action par rapport à ses bénéfices. Il est calculé en divisant le prix actuel de l’action par le bénéfice par action (EPS) sur une période donnée, généralement sur les 12 derniers mois. La formule est la suivante :\n\\[\nPER = \\frac{Prix\\ de\\ l'action}{Bénéfice\\ par\\ action}\n\\]\nUn PER élevé indique que les investisseurs sont prêts à payer davantage pour les bénéfices futurs de l’entreprise, tandis qu’un PER faible suggère que les investisseurs estiment que l’action est sous-évaluée ou que l’entreprise a des perspectives de croissance limitées."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#la-librairie-alpha-vantage",
    "href": "posts/tutorials/fr/valorisation-pe.html#la-librairie-alpha-vantage",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "La librairie Alpha Vantage",
    "text": "La librairie Alpha Vantage\nAlpha Vantage est une plateforme de données financières qui fournit des API pour accéder à diverses informations sur le marché, telles que les cours des actions, les indicateurs techniques, les données sur les devises, les cryptomonnaies et bien d’autres. La librairie Python alpha_vantage permet d’interagir facilement avec ces API.\nLa licence gratuite d’Alpha Vantage permet d’accéder à la plupart des données sans frais. Toutefois, elle est soumise à certaines restrictions, notamment un nombre limité de requêtes par minute et par jour. Pour des usages plus intensifs, des plans payants sont disponibles."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#code-source",
    "href": "posts/tutorials/fr/valorisation-pe.html#code-source",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Code Source",
    "text": "Code Source\nVoici un exemple de programme Python qui utilise la bibliothèque yfinance pour récupérer les valorisations des ETFs secteurs en Europe. Dans cet exemple, je vais utiliser quelques ETFs populaires en Europe pour illustrer le processus. Vous pouvez ajouter ou modifier les symboles d’ETFs dans la liste etfs pour récupérer les valorisations des ETFs que vous souhaitez.\n\n\nCode\nimport os, sys\nroot_path = os.path.join(sys.path[0],'..','..', '..')\nsys.path.append(root_path)\nimport blog_utils\n\ntpl_path = \"https://github.com/vdenoise/templates/raw/master\"\nmpl_tpl_path = f\"{tpl_path}/matplotlib\"\n\n\n\n\nCode\n\nimport keyring\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom alpha_vantage.fundamentaldata import FundamentalData\n\n# Remplacez 'your_api_key' par votre clé API Alpha Vantage\napi_key = keyring.get_password(\"alpha_vantage_api_key\", \"email@email.com\")\nfd = FundamentalData(key=api_key)\n\n# Fonction pour récupérer le Price to Earnings Ratio (P/E Ratio)\ndef get_price_to_earnings_ratio(symbol):\n    data, _ = fd.get_company_overview(symbol)\n    pe_ratio = float(data[\"PERatio\"])\n    return pe_ratio\n\n# Récupérer et afficher les P/E Ratios\nsymbols = [\"AAPL\", \"MSFT\", \"IBM\"]\npe_ratios = [get_price_to_earnings_ratio(symbol) for symbol in symbols]\n\nmatplotlib.rcdefaults() \nblog_utils.apply_right_style()\nplt.bar(symbols, pe_ratios)\nplt.xlabel(\"Symboles\")\nplt.ylabel(\"Price to Earnings Ratio\")\nplt.title(\"Comparaison des PER de différentes actions\")\nplt.show()\n\n\n\nNone\n\n\n\n\n\n\n\n\n\nNotez que les tickers d’ETFs dans etf_tickers sont des exemples. Vous devrez remplacer cette liste par les tickers des ETFs de secteurs en Europe que vous souhaitez analyser. Ce programme récupère le P/E Ratio pour chaque ETF et affiche les résultats à l’écran."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#conclusion",
    "href": "posts/tutorials/fr/valorisation-pe.html#conclusion",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Conclusion",
    "text": "Conclusion\nEn résumé, dans cet article tres court, nous avons montré comment récupérer le Price to Earnings Ratio (PER) de plusieurs actions en utilisant Python, la librairie Alpha Vantage et la bibliothèque de visualisation de données Matplotlib. Le PER est un indicateur financier clé pour évaluer la valorisation d’une action et comparer différentes entreprises."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#sources-de-référence",
    "href": "posts/tutorials/fr/valorisation-pe.html#sources-de-référence",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Sources de référence",
    "text": "Sources de référence\nPour en savoir plus sur Alpha Vantage, la valorisation des actions et l’utilisation du Price to Earnings Ratio dans l’analyse financière, consultez les sources suivantes :\n\nSite officiel d’AlphaVantage : https://www.alphavantage.co/\nDocumentation de la librairie Python alpha_vantage : https://alpha-vantage.readthedocs.io/\nInvestopedia, “Price-to-Earnings Ratio – P/E Ratio” : https://www.investopedia.com/terms/p/price-earningsratio.asp\nCorporate Finance Institute, “Price Earnings Ratio (P/E Ratio)” : https://corporatefinanceinstitute.com/resources/knowledge/valuation/price-earnings-ratio/\nMatplotlib, documentation officielle : https://matplotlib.org/"
  },
  {
    "objectID": "posts/tutorials/en/getting-started-with-eurostat-api.html",
    "href": "posts/tutorials/en/getting-started-with-eurostat-api.html",
    "title": "4 - First Macro-Economic data analysis: using the Eurostat API",
    "section": "",
    "text": "## Connect to Eurostat API with Python using their REST API\nEurostat, the statistical office of the European Union, provides access to a wealth of data on various aspects of the European economy, environment, and society. One way to access this data is through their REST API, which can be easily connected to and queried using Python.\nIn this article, we will walk you through the steps needed to connect to the Eurostat API using Python and build a function to show the connection status to the API. By the end, you’ll be able to retrieve data from Eurostat in a structured and efficient manner."
  },
  {
    "objectID": "posts/tutorials/en/getting-started-with-eurostat-api.html#conclusion",
    "href": "posts/tutorials/en/getting-started-with-eurostat-api.html#conclusion",
    "title": "4 - First Macro-Economic data analysis: using the Eurostat API",
    "section": "Conclusion",
    "text": "Conclusion\nIn this article, we demonstrated how to connect to the Eurostat API using Python and their REST API. We also showed you how to create a simple function to check the connection status to the API.\nWith these tools in hand, you can now access a wide variety of European statistical data and use it in your data analysis or visualization projects. Happy coding!"
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-macos.html",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-macos.html",
    "title": "1-a Setting up a Python Development Workstation (MacOs)",
    "section": "",
    "text": "Ready to enter the world of Python, Visual Studio, and financial analysis? Let’s embark on this journey together. By the end of this guide, you’ll have your finance lab all set for dissecting market trends, optimising portfolios, and much more. Buckle up, let’s set sail! This article requires some knowledge of the terminal, installing softwares"
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#introduction",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#introduction",
    "title": "1-a Setting up a Python Development Workstation (MacOs)",
    "section": "",
    "text": "Ready to enter the world of Python, Visual Studio, and financial analysis? Let’s embark on this journey together. By the end of this guide, you’ll have your finance lab all set for dissecting market trends, optimising portfolios, and much more. Buckle up, let’s set sail! This article requires some knowledge of the terminal, installing softwares"
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-1-install-your-general-tooling",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-1-install-your-general-tooling",
    "title": "1-a Setting up a Python Development Workstation (MacOs)",
    "section": "Step 1: Install Your General Tooling",
    "text": "Step 1: Install Your General Tooling\nWhilst not mandatory, before looking at Python, code editors and various libraries, it’s extremely useful to check that your MacOs is ready to provide you with the best general setup. Terminal windows, bash script might look a bit obscure at first glance, but take it step by step and look at the video linked below to get more clarity on this. This is a marathon, definitely not a sprint.\n\n1.1 Install Homebrew\nHomebrew, affectionately known as brew, is the Swiss Army knife for installing software on macOS. It simplifies the process of managing software on your Mac, making it a breeze to install, uninstall, and update your applications.\nTo install Homebrew, open Terminal and enter:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n\n1.2 Install iTerm2\niTerm2 is an improvement over macOS’s default terminal, offering features such as split panes, search, and customisation. Install it via brew with:\nbrew install --cask iterm2\n\n\n1.3 Install Oh My Zsh:\nZsh, combined with Oh My Zsh, turns the dull default terminal into a powerful and enjoyable tool, complete with themes, plugins, and a vibrant community.\nInstall Oh My Zsh with:\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n::: {.content-visible unless-profile=“presentation”}"
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-2.-setting-up-visual-studio-and-miniconda",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-2.-setting-up-visual-studio-and-miniconda",
    "title": "1-a Setting up a Python Development Workstation (MacOs)",
    "section": "Step 2. Setting Up Visual Studio and Miniconda",
    "text": "Step 2. Setting Up Visual Studio and Miniconda\n\n2.1 Visual Studio\nVisual Studio Code (VS Code) is a lightweight but powerful source code editor that supports debugging, embedded Git control, syntax highlighting, and more. Install VS Code via brew:\nVS Code is a robust and versatile code editor, while Miniconda, a mini version of Anaconda, allows us to create isolated Python environments and manage packages.\nUsing Brew, installed above, is a breeze\nbrew install --cask visual-studio-code\nAlternatively, you can download and install Visual Studio Code from the official website. Follow the prompts to complete the installation process.\n\n\n2.2 Miniconda\nUsing Brew\nbrew install --cask miniconda\nAlternatively, you can download and install Miniconda from the official website. During installation, ensure that you select the option to “Add Miniconda to my PATH environment variable”. This allows you to use conda commands directly in the VS Code terminal."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-3.-setting-up-a-python-virtual-environment",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-3.-setting-up-a-python-virtual-environment",
    "title": "1-a Setting up a Python Development Workstation (MacOs)",
    "section": "Step 3. Setting Up a Python Virtual Environment",
    "text": "Step 3. Setting Up a Python Virtual Environment\n\n3.1 Create the Conda environment\nWith our tools installed, let’s now create a virtual environment to house our finance lab. We’ll use conda to create a new environment named portfolio-geek using Python 3.10.\nOpen VS Code, then open a terminal and type the following command:\nconda create -n portfolio-geek python=3.10\nActivate the portfolio-geek environment by typing:\nconda activate portfolio-geek\n\n\n3.2 Install the key packages for your coding journey\nInside portfolio-geek, we install several vital Python libraries for our financial analysis journey:\n\npandas: A flexible and powerful data manipulation library, essential for handling and processing financial data.\nmatplotlib and seaborn: Two formidable libraries for data visualisation, because finance isn’t just about numbers—it’s about insightful charts too!\nyfinance: An effective library for fetching historical stock data from Yahoo Finance.\npyportfolioopt: An advanced library designed to optimise portfolios, calculate risk and returns, and much more.\n\nInstall these libraries using the following command:\nconda install pandas matplotlib seaborn yfinance pyportfolioopt\n\n\nStep 4. Installing Key Visual Studio Extensions\nThis step is not mandatory but it will be of tremendous help on a day to day basis. VS Code shines with its extensions. Here are a few that will make your life easier:\n\nPython: Gives you a host of Python-specific features like linting, debugging, code formatting, and more.\nPrettier: A code formatter that supports many languages, including Python. Keeps your code clean and professional.\nCode Spell Checker: Like a proof-reader, it catches common spelling mistakes in your code.\n\nYou can install these extensions by searching for them in the VS Code Extensions view (Ctrl + Shift + X) and clicking on “Install”."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-5-launching-a-jupyter-notebook-inside-visual-studio",
    "href": "posts/tutorials/en/setting-up-a-python-workstation-macos.html#step-5-launching-a-jupyter-notebook-inside-visual-studio",
    "title": "1-a Setting up a Python Development Workstation (MacOs)",
    "section": "Step 5 Launching a Jupyter Notebook Inside Visual Studio",
    "text": "Step 5 Launching a Jupyter Notebook Inside Visual Studio\nWith our portfolio-geek environment and VS Code set up, it’s time to dive into some coding. We’ll be using a Jupyter Notebook, a powerful tool allowing you to interweave code and text into a single document.\nCreate a new file with a .ipynb extension. Upon creation, VS Code will prompt you to select a Python interpreter—choose the one corresponding to our portfolio-geek environment.\n\n\nCode\n# Ensure you're in the 'portfolio-geek' environment\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample data\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\n# Plotting\nplt.plot(x, y)\nplt.title(\"Simple Sine Wave Plot\")\nplt.xlabel(\"X axis\")\nplt.ylabel(\"Y axis\")\nplt.show()"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Les 10 formules les plus utilisées en finance de marché\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nPortfolio optimisation with Python\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising Historical Data\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate Financial Risk\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Equity long Term Returns with Python\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n1-b- Setting up a Python Development Workstation (Windows)\n\n\n\n\n\nIn this article we set up our Windows workstation and install all the relevant tools to be efficient in coding in Python.\n\n\n\n\n\nFeb 22, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n1-a Setting up a Python Development Workstation (MacOs)\n\n\n\n\n\nIn this article, we start our journey into Finance and Python coding. Let’s set up our MacOs Workstation and install a few key tools to code efficiently.\n\n\n\n\n\nFeb 20, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n2 - Getting and charting data with Matplotlib\n\n\n\n\n\nIn this article, we start our data analysis journey with Python by getting and charting data, in this case the performance of an ETF using freely available data.\n\n\n\n\n\nJan 25, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n4 - First Macro-Economic data analysis: using the Eurostat API\n\n\n\n\n\nIn this article, we leverage our first API request, using the data provided freely by the Eurostat organisation.\n\n\n\n\n\nJan 15, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Worldbank API (WBGAPI)\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2023\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nObtenir la valorisation de plusieurs titres avec Python et Alpha Vantage\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2023\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "With 20 years of experience in portfolio construction, asset allocation and quantitative research, I have worked across the asset management and capital markets industry’s value chain.\nIn my different roles, I have developed and deployed a wide range range of investment solutions, ranging from Exchange Traded Funds (ETFs), derivatives and investment mandates across most asset classes: Equities, Fixed Income, Commodities, Alternative Assets, Multi-Asset portfolios.\nFind me on Linkedin\n\nWhy this blog?\nWhat struck me the most when I started my career in finance was the knowledge asymetry between finance professionals and end clients. Whilst this gap has been considerably reduced since then, thanks to internet and better information provided, many concepts still sound fairly exotic or technical to many investors.\nHere, I will try to demystify financial analysis and provide ideas and starting points in order to put theory into practice.\nIn most articles, you should be able to copy, run and modify the code behind the analysis. This should help you to directly use many of the tools presented. The entire source is available on Github"
  },
  {
    "objectID": "tutorials_en.html",
    "href": "tutorials_en.html",
    "title": "Getting Started: Quantitative Finance with Python",
    "section": "",
    "text": "1-a Setting up a Python Development Workstation (MacOs)\n\n\n\n\n\nIn this article, we start our journey into Finance and Python coding. Let’s set up our MacOs Workstation and install a few key tools to code efficiently.\n\n\n\n\n\nFeb 20, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n1-b- Setting up a Python Development Workstation (Windows)\n\n\n\n\n\nIn this article we set up our Windows workstation and install all the relevant tools to be efficient in coding in Python.\n\n\n\n\n\nFeb 22, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n2 - Getting and charting data with Matplotlib\n\n\n\n\n\nIn this article, we start our data analysis journey with Python by getting and charting data, in this case the performance of an ETF using freely available data.\n\n\n\n\n\nJan 25, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n4 - First Macro-Economic data analysis: using the Eurostat API\n\n\n\n\n\nIn this article, we leverage our first API request, using the data provided freely by the Eurostat organisation.\n\n\n\n\n\nJan 15, 2024\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Equity long Term Returns with Python\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#formula",
    "href": "posts/data-driven-minute/ddm1-volatility.html#formula",
    "title": "Calculating Volatility",
    "section": "Formula:",
    "text": "Formula:\n\\[\n\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(R_i - \\mu)^2}{n-1}}\n\\]"
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#steps",
    "href": "posts/data-driven-minute/ddm1-volatility.html#steps",
    "title": "Calculating Volatility",
    "section": "Steps:",
    "text": "Steps:\n\nCalculate the average return (( )).\nSubtract the average return from each individual return (( R_i - )).\nSquare these differences.\nSum up all the squared differences.\nDivide by the number of returns minus one (( n-1 )).\nTake the square root of the result.\n\n\n\n[*********************100%***********************]  1 of 1 completed"
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#calculating-volatility",
    "href": "posts/data-driven-minute/ddm1-volatility.html#calculating-volatility",
    "title": "Calculating Volatility",
    "section": "Calculating Volatility",
    "text": "Calculating Volatility\nFormula:\n\\[\n\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(R_i - \\mu)^2}{n-1}}\n\\]\nSteps:\n\nCalculate the average return (( )).\nSubtract the average return from each individual return (( R_i - )).\nSquare these differences.\nSum up all the squared differences.\nDivide by the number of returns minus one (( n-1 )).\nTake the square root of the result.\n\n\n\n[*********************100%***********************]  1 of 1 completed"
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#section",
    "href": "posts/data-driven-minute/ddm1-volatility.html#section",
    "title": "Portfolio Geek",
    "section": "",
    "text": "Hey there! Imagine you’re driving to work every day. Some days, you zip through traffic without a hitch. Other days, you get stuck in jams or hit every red light. Now, think of the ups and downs of your drive as return volatility in the stock market.\n\n\n\\[\n\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(R_i - \\mu)^2}{n-1}}\n\\]\n\n\n\n\nCalculate the average return (\\(\\mu\\)).\nSubtract the average return from each individual return \\(R_{i} - \\mu\\).\nSquare these differences.\nSum up all the squared differences.\nDivide by the number of returns minus one (\\(n-1\\)).\nTake the square root of the result."
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#section-1",
    "href": "posts/data-driven-minute/ddm1-volatility.html#section-1",
    "title": "Portfolio Geek",
    "section": "",
    "text": "Sum up all the squared differences.\nDivide by the number of returns minus one (( n-1 )).\nTake the square root of the result."
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#chart",
    "href": "posts/data-driven-minute/ddm1-volatility.html#chart",
    "title": "Portfolio Geek",
    "section": "Chart",
    "text": "Chart"
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#background-image-green-screen.png-background-size-cover-background-repeat-no-repeat",
    "href": "posts/data-driven-minute/ddm1-volatility.html#background-image-green-screen.png-background-size-cover-background-repeat-no-repeat",
    "title": "Portfolio Geek",
    "section": "{background-image: “green-screen.png”; background-size: “cover”, background-repeat: “no-repeat”}",
    "text": "{background-image: “green-screen.png”; background-size: “cover”, background-repeat: “no-repeat”}"
  },
  {
    "objectID": "posts/data-driven-minute/ddm1-volatility.html#section-2",
    "href": "posts/data-driven-minute/ddm1-volatility.html#section-2",
    "title": "Portfolio Geek",
    "section": "",
    "text": "AttributeError: 'tuple' object has no attribute 'patch'"
  },
  {
    "objectID": "posts/data-driven-minute/ddm-template.html#section",
    "href": "posts/data-driven-minute/ddm-template.html#section",
    "title": "Portfolio Geek",
    "section": "",
    "text": "Hey there! Imagine you’re driving to work every day. Some days, you zip through traffic without a hitch. Other days, you get stuck in jams or hit every red light. Now, think of the ups and downs of your drive as return volatility in the stock market.\n\n\n\\[\n\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n}(R_i - \\mu)^2}{n-1}}\n\\]\n\n\n\n\nCalculate the average return (\\(\\mu\\)).\nSubtract the average return from each individual return \\(R_{i} - \\mu\\).\nSquare these differences.\nSum up all the squared differences.\nDivide by the number of returns minus one (\\(n-1\\)).\nTake the square root of the result."
  },
  {
    "objectID": "posts/daily-curation.html",
    "href": "posts/daily-curation.html",
    "title": "Portfolio Construction",
    "section": "",
    "text": "15/07/2024: Economics, Indexing, Quant and Coding Links\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html",
    "title": "15/07/2024: Economics, Indexing, Quant and Coding Links",
    "section": "",
    "text": "Title\nSource\nSummary\n\n\n\n\nHome Inventory Grows 34.5% YoY but Still Struggles to Meet Pre-Pandemic Levels: Insight into Current Market Trends\nCalculated Risk\nActive inventory in the existing home market increased by 34.5% YoY, marking the 35th consecutive week of growth. New listings declined by 4.9% from last year. Supply constraints persist.\n\n\nNavigating Market Peaks: What to Know Before Buying a Home Amidst Soaring Prices and Mortgage Rates\nA Wealth of Common Sense\nHousing prices have risen significantly, and the author warns that potential homebuyers may face low returns. They discuss two scenarios: a 20% price drop or stagnant prices for the decade. The author believes that for homeowners planning to stay, these scenarios wouldn’t have a significant impact. They highlight the potential risks for those buying right now and emphasize that a house should be more than just a financial investment.\n\n\nBloomberg Donates $1 Billion to Johns Hopkins for Medical School Free Tuition and Comprehensive Student Support\nNPR\nJohns Hopkins University’s medical school will offer free tuition to most students, thanks to a $1 billion gift from Michael Bloomberg’s philanthropic organization."
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#theme-title-source-summary-link",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#theme-title-source-summary-link",
    "title": "15/07/2024: Coding and Quant Links",
    "section": "",
    "text": "coding | Make SQLite Smarter and Faster with Vectorlite: Your Go-To Extension for Enhanced Vector Search in AI Applications | Reddit | Vectorlite is a fast and tunable vector search extension for SQLite. It offers fast ANN-search, metadata filter pushdown support, and index serde support, among other features.\neconomics Home Inventory Grows 34.5% YoY but Still Struggles to Meet Pre-Pandemic Levels: Insight into Current Market Trends Calculated Risk Active inventory in the existing home market increased by 34.5% YoY, marking the 35th consecutive week of growth. New listings declined by 4.9% from last year. Supply constraints persist. http://www.calculatedriskblog.com/2024/07/realtorcom-reports-active-inventory-up_01292103715.html\neconomics Navigating Market Peaks: What to Know Before Buying a Home Amidst Soaring Prices and Mortgage Rates A Wealth of Common Sense Housing prices have risen significantly, and the author warns that potential homebuyers may face low returns. They discuss two scenarios: a 20% price drop or stagnant prices for the decade. The author believes that for homeowners planning to stay, these scenarios wouldn’t have a significant impact. They highlight the potential risks for those buying right now and emphasize that a house should be more than just a financial investment. https://awealthofcommonsense.com/2024/07/buying-a-house-at-the-top-of-the-market/\neconomics Bloomberg Donates $1 Billion to Johns Hopkins for Medical School Free Tuition and Comprehensive Student Support NPR Johns Hopkins University’s medical school will offer free tuition to most students, thanks to a $1 billion gift from Michael Bloomberg’s philanthropic organization. https://www.npr.org/2024/07/09/g-s1-8876/johns-hopkins-medical-school-bloomberg\netf How Passive Investing Subtly Shifts Market Dynamics: A New Perspective from GMO Experts GMO Quarterly Letter The impact of passive investing on the stock market is less significant than believed, according to GMO. The firm argues that passive investing has not made markets less efficient and that the future impact will be muted. https://www.institutionalinvestor.com/article/2dgy5jctx2rb7g3wv2juo/portfolio/gmo-passive-investings-impact-has-been-overblown-but-its-not-negligible etf Why Concerns About Index Funds Being a Bubble May Be Overstated: Insights and Historical Context Retirement Investing Today The article explores concerns about index funds being a bubble, but argues that these concerns are unfounded due to the historical success of indexing and the continued demand for active management. https://jlcollinsnh.com/2024/07/09/are-index-funds-a-bubble/ quant Why Investors Might Want to Pay Attention to Market Moves on July 1st Quantifiable Edges July has historically seen the highest win percentage and largest average trade on the first day of the month, potentially due to 401k inflows. In the past 13 instances, July’s day-1 performance has always been positive. https://quantifiableedges.com/july-remains-king-of-day-1-performance/ quant Simplifying Multifactor Credit Portfolios: Why Integrated Beats Mixing for Better Returns and Lower Risk Quantpedia The integrated approach is found to be better for constructing long-only multifactor credit portfolios, according to a research paper. It reduces downside risk and can achieve attractive risk-adjusted returns. https://quantpedia.com/how-to-construct-a-long-only-multifactor-credit-portfolio/ quant Maximize Investment Strategy: Boost Returns by Merging Forecasts from Top Financial Institutions for Better Predictions Capital Plug Combining capital market assumptions from multiple institutions improves forecasting accuracy for investors by averaging forecasts and reducing reliance on a single institution’s forecast. https://portfoliooptimizer.io/blog/capital-market-assumptions-combining-institutions-forecasts-for-improved-accuracy/ quant Balancing Risk and Reward: Smart Strategies for Navigating Prolonged Yield Curve Inversions in Your Investment Portfolio Quantpedia The Pragmatic Asset Allocation Model focuses on tax-efficient investing and uses the yield curve inversion signal to determine when to move to a hedging portfolio. An amended version of the model switches to equities after 12 months of the signal. Long-term results show negligible differences between the original and amended versions. The decision between the two versions depends on individual risk tolerance and preferences. https://quantpedia.com/a-few-thoughts-on-pragmatic-asset-allocation/ quant Unlocking Market Insights: How NLP Transforms News and Corporate Filings into Investment Gold QuantRocket and Brain NLP techniques are revolutionizing alternative data analysis, allowing investors to extract insights from news articles, SEC filings, and earnings calls. Brain’s datasets and case studies demonstrate their effectiveness. https://www.quantrocket.com/blog/brain-alternative-data quant Why Future Corporate Earnings Are More Reliable Than Federal Inflation Projections Navigating the Earnings Season In the upcoming earnings season, corporate outlooks on inflation and pricing will contrast with the uncertainty from the Federal Open Market Committee (FOMC). https://www.wisdomtree.com/investments/blog/2024/07/11/navigating-earnings-season-the-coming-outlooks quant Enhance Your Data Analysis: Discover the Power of Time Series Smoothing Techniques with Savitzky-Golay Filter Medium Smoothing time series data helps to detect meaningful patterns. Moving average and Savitzky-Golay filter are popular smoothing techniques. While moving average is simple, it lacks precision, whereas Savitzky-Golay filter preserves important characteristics like peaks and troughs. https://medium.com/bip-xtech/stop-using-moving-average-to-smooth-your-time-series-2179af9ed59b"
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#theme-title-source-summary",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#theme-title-source-summary",
    "title": "15/07/2024: Coding and Quant Links",
    "section": "",
    "text": "coding | Make SQLite Smarter and Faster with Vectorlite: Your Go-To Extension for Enhanced Vector Search in AI Applications | Reddit | Vectorlite is a fast and tunable vector search extension for SQLite. It offers fast ANN-search, metadata filter pushdown support, and index serde support, among other features.|\neconomics | Home Inventory Grows 34.5% YoY but Still Struggles to Meet Pre-Pandemic Levels: Insight into Current Market Trends | Calculated Risk | Active inventory in the existing home market increased by 34.5% YoY, marking the 35th consecutive week of growth. New listings declined by 4.9% from last year. Supply constraints persist. |\neconomics Navigating Market Peaks: What to Know Before Buying a Home Amidst Soaring Prices and Mortgage Rates A Wealth of Common Sense Housing prices have risen significantly, and the author warns that potential homebuyers may face low returns. They discuss two scenarios: a 20% price drop or stagnant prices for the decade. The author believes that for homeowners planning to stay, these scenarios wouldn’t have a significant impact. They highlight the potential risks for those buying right now and emphasize that a house should be more than just a financial investment. https://awealthofcommonsense.com/2024/07/buying-a-house-at-the-top-of-the-market/\neconomics Bloomberg Donates $1 Billion to Johns Hopkins for Medical School Free Tuition and Comprehensive Student Support NPR Johns Hopkins University’s medical school will offer free tuition to most students, thanks to a $1 billion gift from Michael Bloomberg’s philanthropic organization. https://www.npr.org/2024/07/09/g-s1-8876/johns-hopkins-medical-school-bloomberg\netf How Passive Investing Subtly Shifts Market Dynamics: A New Perspective from GMO Experts GMO Quarterly Letter The impact of passive investing on the stock market is less significant than believed, according to GMO. The firm argues that passive investing has not made markets less efficient and that the future impact will be muted. https://www.institutionalinvestor.com/article/2dgy5jctx2rb7g3wv2juo/portfolio/gmo-passive-investings-impact-has-been-overblown-but-its-not-negligible etf Why Concerns About Index Funds Being a Bubble May Be Overstated: Insights and Historical Context Retirement Investing Today The article explores concerns about index funds being a bubble, but argues that these concerns are unfounded due to the historical success of indexing and the continued demand for active management. https://jlcollinsnh.com/2024/07/09/are-index-funds-a-bubble/ quant Why Investors Might Want to Pay Attention to Market Moves on July 1st Quantifiable Edges July has historically seen the highest win percentage and largest average trade on the first day of the month, potentially due to 401k inflows. In the past 13 instances, July’s day-1 performance has always been positive. https://quantifiableedges.com/july-remains-king-of-day-1-performance/ quant Simplifying Multifactor Credit Portfolios: Why Integrated Beats Mixing for Better Returns and Lower Risk Quantpedia The integrated approach is found to be better for constructing long-only multifactor credit portfolios, according to a research paper. It reduces downside risk and can achieve attractive risk-adjusted returns. https://quantpedia.com/how-to-construct-a-long-only-multifactor-credit-portfolio/ quant Maximize Investment Strategy: Boost Returns by Merging Forecasts from Top Financial Institutions for Better Predictions Capital Plug Combining capital market assumptions from multiple institutions improves forecasting accuracy for investors by averaging forecasts and reducing reliance on a single institution’s forecast. https://portfoliooptimizer.io/blog/capital-market-assumptions-combining-institutions-forecasts-for-improved-accuracy/ quant Balancing Risk and Reward: Smart Strategies for Navigating Prolonged Yield Curve Inversions in Your Investment Portfolio Quantpedia The Pragmatic Asset Allocation Model focuses on tax-efficient investing and uses the yield curve inversion signal to determine when to move to a hedging portfolio. An amended version of the model switches to equities after 12 months of the signal. Long-term results show negligible differences between the original and amended versions. The decision between the two versions depends on individual risk tolerance and preferences. https://quantpedia.com/a-few-thoughts-on-pragmatic-asset-allocation/ quant Unlocking Market Insights: How NLP Transforms News and Corporate Filings into Investment Gold QuantRocket and Brain NLP techniques are revolutionizing alternative data analysis, allowing investors to extract insights from news articles, SEC filings, and earnings calls. Brain’s datasets and case studies demonstrate their effectiveness. https://www.quantrocket.com/blog/brain-alternative-data quant Why Future Corporate Earnings Are More Reliable Than Federal Inflation Projections Navigating the Earnings Season In the upcoming earnings season, corporate outlooks on inflation and pricing will contrast with the uncertainty from the Federal Open Market Committee (FOMC). https://www.wisdomtree.com/investments/blog/2024/07/11/navigating-earnings-season-the-coming-outlooks quant Enhance Your Data Analysis: Discover the Power of Time Series Smoothing Techniques with Savitzky-Golay Filter Medium Smoothing time series data helps to detect meaningful patterns. Moving average and Savitzky-Golay filter are popular smoothing techniques. While moving average is simple, it lacks precision, whereas Savitzky-Golay filter preserves important characteristics like peaks and troughs. https://medium.com/bip-xtech/stop-using-moving-average-to-smooth-your-time-series-2179af9ed59b"
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#economics-home-inventory-grows-34.5-yoy-but-still-struggles-to-meet-pre-pandemic-levels-insight-into-current-market-trends-calculated-risk-active-inventory-in-the-existing-home-market-increased-by-34.5-yoy-marking-the-35th-consecutive-week-of-growth.-new-listings-declined-by-4.9-from-last-year.-supply-constraints-persist.",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#economics-home-inventory-grows-34.5-yoy-but-still-struggles-to-meet-pre-pandemic-levels-insight-into-current-market-trends-calculated-risk-active-inventory-in-the-existing-home-market-increased-by-34.5-yoy-marking-the-35th-consecutive-week-of-growth.-new-listings-declined-by-4.9-from-last-year.-supply-constraints-persist.",
    "title": "15/07/2024: Coding and Quant Links",
    "section": "| economics | Home Inventory Grows 34.5% YoY but Still Struggles to Meet Pre-Pandemic Levels: Insight into Current Market Trends | Calculated Risk | Active inventory in the existing home market increased by 34.5% YoY, marking the 35th consecutive week of growth. New listings declined by 4.9% from last year. Supply constraints persist. |",
    "text": "| economics | Home Inventory Grows 34.5% YoY but Still Struggles to Meet Pre-Pandemic Levels: Insight into Current Market Trends | Calculated Risk | Active inventory in the existing home market increased by 34.5% YoY, marking the 35th consecutive week of growth. New listings declined by 4.9% from last year. Supply constraints persist. |\neconomics Navigating Market Peaks: What to Know Before Buying a Home Amidst Soaring Prices and Mortgage Rates A Wealth of Common Sense Housing prices have risen significantly, and the author warns that potential homebuyers may face low returns. They discuss two scenarios: a 20% price drop or stagnant prices for the decade. The author believes that for homeowners planning to stay, these scenarios wouldn’t have a significant impact. They highlight the potential risks for those buying right now and emphasize that a house should be more than just a financial investment. https://awealthofcommonsense.com/2024/07/buying-a-house-at-the-top-of-the-market/\neconomics Bloomberg Donates $1 Billion to Johns Hopkins for Medical School Free Tuition and Comprehensive Student Support NPR Johns Hopkins University’s medical school will offer free tuition to most students, thanks to a $1 billion gift from Michael Bloomberg’s philanthropic organization. https://www.npr.org/2024/07/09/g-s1-8876/johns-hopkins-medical-school-bloomberg\netf How Passive Investing Subtly Shifts Market Dynamics: A New Perspective from GMO Experts GMO Quarterly Letter The impact of passive investing on the stock market is less significant than believed, according to GMO. The firm argues that passive investing has not made markets less efficient and that the future impact will be muted. https://www.institutionalinvestor.com/article/2dgy5jctx2rb7g3wv2juo/portfolio/gmo-passive-investings-impact-has-been-overblown-but-its-not-negligible etf Why Concerns About Index Funds Being a Bubble May Be Overstated: Insights and Historical Context Retirement Investing Today The article explores concerns about index funds being a bubble, but argues that these concerns are unfounded due to the historical success of indexing and the continued demand for active management. https://jlcollinsnh.com/2024/07/09/are-index-funds-a-bubble/ quant Why Investors Might Want to Pay Attention to Market Moves on July 1st Quantifiable Edges July has historically seen the highest win percentage and largest average trade on the first day of the month, potentially due to 401k inflows. In the past 13 instances, July’s day-1 performance has always been positive. https://quantifiableedges.com/july-remains-king-of-day-1-performance/ quant Simplifying Multifactor Credit Portfolios: Why Integrated Beats Mixing for Better Returns and Lower Risk Quantpedia The integrated approach is found to be better for constructing long-only multifactor credit portfolios, according to a research paper. It reduces downside risk and can achieve attractive risk-adjusted returns. https://quantpedia.com/how-to-construct-a-long-only-multifactor-credit-portfolio/ quant Maximize Investment Strategy: Boost Returns by Merging Forecasts from Top Financial Institutions for Better Predictions Capital Plug Combining capital market assumptions from multiple institutions improves forecasting accuracy for investors by averaging forecasts and reducing reliance on a single institution’s forecast. https://portfoliooptimizer.io/blog/capital-market-assumptions-combining-institutions-forecasts-for-improved-accuracy/ quant Balancing Risk and Reward: Smart Strategies for Navigating Prolonged Yield Curve Inversions in Your Investment Portfolio Quantpedia The Pragmatic Asset Allocation Model focuses on tax-efficient investing and uses the yield curve inversion signal to determine when to move to a hedging portfolio. An amended version of the model switches to equities after 12 months of the signal. Long-term results show negligible differences between the original and amended versions. The decision between the two versions depends on individual risk tolerance and preferences. https://quantpedia.com/a-few-thoughts-on-pragmatic-asset-allocation/ quant Unlocking Market Insights: How NLP Transforms News and Corporate Filings into Investment Gold QuantRocket and Brain NLP techniques are revolutionizing alternative data analysis, allowing investors to extract insights from news articles, SEC filings, and earnings calls. Brain’s datasets and case studies demonstrate their effectiveness. https://www.quantrocket.com/blog/brain-alternative-data quant Why Future Corporate Earnings Are More Reliable Than Federal Inflation Projections Navigating the Earnings Season In the upcoming earnings season, corporate outlooks on inflation and pricing will contrast with the uncertainty from the Federal Open Market Committee (FOMC). https://www.wisdomtree.com/investments/blog/2024/07/11/navigating-earnings-season-the-coming-outlooks quant Enhance Your Data Analysis: Discover the Power of Time Series Smoothing Techniques with Savitzky-Golay Filter Medium Smoothing time series data helps to detect meaningful patterns. Moving average and Savitzky-Golay filter are popular smoothing techniques. While moving average is simple, it lacks precision, whereas Savitzky-Golay filter preserves important characteristics like peaks and troughs. https://medium.com/bip-xtech/stop-using-moving-average-to-smooth-your-time-series-2179af9ed59b"
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#economics",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#economics",
    "title": "15/07/2024: Economics, Indexing, Quant and Coding Links",
    "section": "",
    "text": "Title\nSource\nSummary\n\n\n\n\nHome Inventory Grows 34.5% YoY but Still Struggles to Meet Pre-Pandemic Levels: Insight into Current Market Trends\nCalculated Risk\nActive inventory in the existing home market increased by 34.5% YoY, marking the 35th consecutive week of growth. New listings declined by 4.9% from last year. Supply constraints persist.\n\n\nNavigating Market Peaks: What to Know Before Buying a Home Amidst Soaring Prices and Mortgage Rates\nA Wealth of Common Sense\nHousing prices have risen significantly, and the author warns that potential homebuyers may face low returns. They discuss two scenarios: a 20% price drop or stagnant prices for the decade. The author believes that for homeowners planning to stay, these scenarios wouldn’t have a significant impact. They highlight the potential risks for those buying right now and emphasize that a house should be more than just a financial investment.\n\n\nBloomberg Donates $1 Billion to Johns Hopkins for Medical School Free Tuition and Comprehensive Student Support\nNPR\nJohns Hopkins University’s medical school will offer free tuition to most students, thanks to a $1 billion gift from Michael Bloomberg’s philanthropic organization."
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#index-investing",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#index-investing",
    "title": "15/07/2024: Economics, Indexing, Quant and Coding Links",
    "section": "Index Investing",
    "text": "Index Investing\n\n\n\nTitle\nSource\nSummary\n\n\n\n\nHow Passive Investing Subtly Shifts Market Dynamics: A New Perspective from GMO Experts\nGMO Quarterly Letter\nThe impact of passive investing on the stock market is less significant than believed, according to GMO. The firm argues that passive investing has not made markets less efficient and that the future impact will be muted.\n\n\nWhy Concerns About Index Funds Being a Bubble May Be Overstated: Insights and Historical Context\nRetirement Investing Today\nThe article explores concerns about index funds being a bubble, but argues that these concerns are unfounded due to the historical success of indexing and the continued demand for active management."
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#quantitative-investing",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#quantitative-investing",
    "title": "15/07/2024: Economics, Indexing, Quant and Coding Links",
    "section": "Quantitative Investing",
    "text": "Quantitative Investing\n\n\n\nTitle\nSource\nSummary\n\n\n\n\nWhy Investors Might Want to Pay Attention to Market Moves on July 1st\nQuantifiable Edges\nJuly has historically seen the highest win percentage and largest average trade on the first day of the month, potentially due to 401k inflows. In the past 13 instances, July’s day-1 performance has always been positive.\n\n\nSimplifying Multifactor Credit Portfolios: Why Integrated Beats Mixing for Better Returns and Lower Risk\nQuantpedia\nThe integrated approach is found to be better for constructing long-only multifactor credit portfolios, according to a research paper. It reduces downside risk and can achieve attractive risk-adjusted returns.\n\n\nMaximize Investment Strategy: Boost Returns by Merging Forecasts from Top Financial Institutions for Better Predictions\nCapital Plug\nCombining capital market assumptions from multiple institutions improves forecasting accuracy for investors by averaging forecasts and reducing reliance on a single institution’s forecast.\n\n\nBalancing Risk and Reward: Smart Strategies for Navigating Prolonged Yield Curve Inversions in Your Investment Portfolio\nQuantpedia\nThe Pragmatic Asset Allocation Model focuses on tax-efficient investing and uses the yield curve inversion signal to determine when to move to a hedging portfolio. An amended version of the model switches to equities after 12 months of the signal. Long-term results show negligible differences between the original and amended versions. The decision between the two versions depends on individual risk tolerance and preferences.\n\n\nUnlocking Market Insights: How NLP Transforms News and Corporate Filings into Investment Gold\nQuantRocket and Brain\nNLP techniques are revolutionizing alternative data analysis, allowing investors to extract insights from news articles, SEC filings, and earnings calls. Brain’s datasets and case studies demonstrate their effectiveness.\n\n\nEnhance Your Data Analysis: Discover the Power of Time Series Smoothing Techniques with Savitzky-Golay Filter\nMedium\nSmoothing time series data helps to detect meaningful patterns. Moving average and Savitzky-Golay filter are popular smoothing techniques. While moving average is simple, it lacks precision, whereas Savitzky-Golay filter preserves important characteristics like peaks and troughs."
  },
  {
    "objectID": "posts/daily-curation/2024-07-15_daily-curation.html#tech-and-coding",
    "href": "posts/daily-curation/2024-07-15_daily-curation.html#tech-and-coding",
    "title": "15/07/2024: Economics, Indexing, Quant and Coding Links",
    "section": "Tech and Coding",
    "text": "Tech and Coding\n\n\n\nTitle\nSource\nSummary\n\n\n\n\ncoding\nMake SQLite Smarter and Faster with Vectorlite: Your Go-To Extension for Enhanced Vector Search in AI Applications\nReddit"
  }
]