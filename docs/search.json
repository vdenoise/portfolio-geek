[
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html",
    "title": "Estimate Financial Risk",
    "section": "",
    "text": "## Introduction In today’s session, we will"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-close-price",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-close-price",
    "title": "Estimate Financial Risk",
    "section": "Plot Historical Close Price",
    "text": "Plot Historical Close Price\n\n\nCode\ntpl_path = \"https://github.com/vdenoise/templates/raw/master\"\nmpl_tpl_path = f\"{tpl_path}/matplotlib\"\n\nplt.style.use(f\"{mpl_tpl_path}/dracula_slide.mplstyle\")\ndata.resample(\"W\").last().plot(figsize=(4,6));\nplt.ylabel(\"Wealth Curve\")  \nmatplotx.line_labels()  \n\nplt.savefig(\"output/wealth_curve_spy.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-returns",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#plot-historical-returns",
    "title": "Estimate Financial Risk",
    "section": "Plot Historical Returns",
    "text": "Plot Historical Returns\n\n\nCode\nplt.figure(figsize=(8, 6))\ndata_bar = data.resample(\"W\").last().pct_change().multiply(100)\nindex = data_bar.index\nindex = [pd.to_datetime(date, format='%Y-%m-%d').date() for date in index]\ndata_bar.index = index\nax = data_bar.plot.bar()\nplt.ylabel(\"Weekly Return (%)\")\nax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\nplt.gcf().autofmt_xdate()\nplt.savefig(\"output/weekly_returns_spy.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#sorted-weekly-returns",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#sorted-weekly-returns",
    "title": "Estimate Financial Risk",
    "section": "Sorted Weekly Returns",
    "text": "Sorted Weekly Returns\n\n\nCode\nsorted_returns = data.resample(\"W\").last().pct_change().multiply(100).sort_values()\nsorted_returns.plot(figsize=(8, 6));\nplt.savefig(\"output/sorted_weekly_returns_spy.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#return-distribution",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#return-distribution",
    "title": "Estimate Financial Risk",
    "section": "Return Distribution",
    "text": "Return Distribution\n\n\nCode\ndata_bar.hist(bins=100, figsize=(8,6));\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(8, 6))\nax = sns.kdeplot(data_bar)\nmean = data_bar.mean()\nstd = data_bar.std()\nN = 10\nfor i in [1, 2, 3]:\n    x1 = np.linspace(mean - i*std, mean - (i - 1)*std, N)\n    x2 = np.linspace(mean - (i - 1)*std, mean + (i - 1)*std, N)\n    x3 = np.linspace(mean + (i - 1)*std, mean + i*std, N)\n    x = np.concatenate((x1, x2, x3))\n    x = np.where((mean - (i - 1)*std < x) & (x < mean + (i - 1)*std), np.nan, x)\n    y = norm.pdf(x, mean, std)\n    ax.fill_between(x, y, alpha=0.5)\n\nplt.xlabel(\"SPY Weekly Returns (in %, US Dollar)\")\nplt.ylabel(\"Probability Density Function\")\n#plt.xticks(ticks=range(0, 10))\nplt.grid()\n\nplt.show()"
  },
  {
    "objectID": "posts/risk_and_return/estimating-portfolio-risk.html#historical-volatility",
    "href": "posts/risk_and_return/estimating-portfolio-risk.html#historical-volatility",
    "title": "Estimate Financial Risk",
    "section": "Historical Volatility",
    "text": "Historical Volatility\n\n\nCode\nplt.figure(figsize=(8, 6))\nplt.savefig(\"output/wealth_curve_spy.png\" );\ndata.resample(\"W\").last().pct_change().rolling(52).std().multiply(math.sqrt(52)).plot(secondary_y=True)\nmatplotx.line_labels() \nplt.savefig(\"output/wealth_curve_spy_with_vol.png\" );\n\n\n\n\n\n\n\nCode\nplt.figure(figsize=(8, 6))\ndata.resample(\"W\").last().pct_change().rolling(52).std().multiply(math.sqrt(52)).plot(secondary_y=False)\nmatplotx.line_labels()\nplt.savefig(\"output/vol_spy.png\" );\ndata_agg.resample(\"W\").last().pct_change().rolling(52).std().multiply(math.sqrt(52)).plot(secondary_y=False)\nmatplotx.line_labels()\nplt.savefig(\"output/vol_spy_with_agg.png\" );"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#rendement-moyen",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#rendement-moyen",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "1. Rendement moyen",
    "text": "1. Rendement moyen\n\nUsage\nLe rendement moyen est utilisé pour estimer le rendement d’un actif financier sur une période donnée.\n\n\nContexte\nLe rendement moyen est souvent utilisé pour comparer les performances de différents actifs financiers ou pour évaluer l’efficacité d’un portefeuille d’investissement.\n\n\nFormule\n\\(\\mu = \\frac{1}{n}\\sum_{i=1}^{n}(R_i)\\)\n\n\nCode\nimport yfinance as yf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nticker = 'AAPL'\ndata = yf.download(ticker, start='2020-01-01', end='2021-01-01')['Adj Close']\nreturns = data.pct_change().dropna()\nmean_return = np.mean(returns)\n\nplt.plot(returns)\nplt.axhline(y=mean_return, color='r', linestyle='--', label=f'Mean Return: {mean_return:.4f}')\nplt.xlabel('Date')\nplt.ylabel('Returns')\nplt.legend()\nplt.show()\n\n\n[*********************100%***********************]  1 of 1 completed"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#volatilité",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#volatilité",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "2. Volatilité",
    "text": "2. Volatilité\n\nUsage\nLa volatilité est utilisée pour mesurer le risque associé à un actif financier en estimant l’écart-type de ses rendements.\n\n\nContexte\nUne volatilité élevée indique un actif plus risqué, tandis qu’une volatilité faible indique un actif moins risqué. La volatilité est souvent utilisée pour évaluer les fluctuations de prix et le risque de marché.\n\n\nFormule\n\\(\\sigma = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(R_i - \\mu)^2}\\)\n\n\nCode\nvolatility = np.std(returns, ddof=1)\n\nplt.plot(returns)\nplt.axhline(y=0, color='black', linestyle='-')\nplt.axhline(y=volatility, color='r', linestyle='--', label=f'Volatility: {volatility:.4f}')\nplt.axhline(y=-volatility, color='r', linestyle='--')\nplt.xlabel('Date')\nplt.ylabel('Returns')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#ratio-de-sharpe",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#ratio-de-sharpe",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "3. Ratio de Sharpe",
    "text": "3. Ratio de Sharpe\n\nUsage\nLe ratio de Sharpe est utilisé pour évaluer la performance ajustée au risque d’un actif financier ou d’un portefeuille d’investissement.\n\n\nContexte\nUn ratio de Sharpe élevé indique une meilleure performance ajustée au risque, tandis qu’un ratio de Sharpe faible indique une moins bonne performance. Le ratio de Sharpe est souvent utilisé pour comparer les performances de différents actifs ou portefeuilles.\n\n\nFormule\n\\(S = \\frac{\\mu - r_f}{\\sigma}\\)\n\n\nCode\nrisk_free_rate = 0.02  # Assuming a 2% annual risk-free rate\nsharpe_ratio = (mean_return - risk_free_rate) /volatility\n\nplt.plot(returns)\nplt.axhline(y=0, color='black', linestyle='-')\nplt.axhline(y=mean_return, color='g', linestyle='--', label=f'Mean Return: {mean_return:.4f}')\nplt.axhline(y=volatility, color='r', linestyle='--', label=f'Volatility: {volatility:.4f}')\nplt.axhline(y=-volatility, color='r', linestyle='--')\nplt.xlabel('Date')\nplt.ylabel('Returns')\nplt.legend()\nplt.show()\n\nprint(f'Sharpe Ratio: {sharpe_ratio:.4f}')\n\n\n\n\n\nSharpe Ratio: -0.5871"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#bêta",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#bêta",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "4. Bêta",
    "text": "4. Bêta\n\nUsage\nLa bêta est utilisée pour mesurer la sensibilité d’un actif financier par rapport aux mouvements du marché.\n\n\nContexte\nUn bêta supérieur à 1 indique un actif plus sensible aux mouvements du marché, tandis qu’un bêta inférieur à 1 indique un actif moins sensible. La bêta est souvent utilisée pour évaluer le risque systématique d’un actif ou d’un portefeuille d’investissement.\n\n\nFormule\n\\(\\beta = \\frac{\\mathrm{Cov}(R_p, R_m)}{\\mathrm{Var}(R_m)}\\)\n\n\nCode\nmarket_ticker = '^GSPC'\nmarket_data = yf.download(market_ticker, start='2020-01-01', end='2021-01-01')['Adj Close']\nmarket_returns = market_data.pct_change().dropna()\n\ncov_matrix = np.cov(returns, market_returns)\nbeta = cov_matrix[0][1] / cov_matrix[1][1]\n\nprint(f'Beta: {beta:.4f}')\n\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nBeta: 1.1225"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#alpha-de-jensen",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#alpha-de-jensen",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "5. Alpha de Jensen",
    "text": "5. Alpha de Jensen\n\nUsage\nL’alpha de Jensen est utilisé pour évaluer la performance d’un actif financier ou d’un portefeuille d’investissement par rapport à un indice de marché, en tenant compte du risque.\n\n\nContexte\nUn alpha de Jensen positif indique une surperformance par rapport à l’indice de marché, tandis qu’un alpha de Jensen négatif indique une sous-performance. L’alpha de Jensen est souvent utilisé pour évaluer la performance d’un gestionnaire de portefeuille.\n\n\nFormule\n\\(\\alpha = R_p - (R_f + \\beta (R_m - R_f))\\)\n\n\nCode\nalpha = mean_return - (risk_free_rate + beta * (np.mean(market_returns) - risk_free_rate))\n\nprint(f'Alpha de Jensen: {alpha:.4f}')\n\n\nAlpha de Jensen: 0.0043"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#duration-de-macaulay",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#duration-de-macaulay",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "6. Duration de Macaulay",
    "text": "6. Duration de Macaulay\n\nUsage\nLa duration de Macaulay est utilisée pour mesurer la sensibilité d’un titre à taux fixe, tel qu’une obligation, aux variations des taux d’intérêt.\n\n\nContexte\nUne duration de Macaulay élevée indique un titre plus sensible aux variations des taux d’intérêt, tandis qu’une duration de Macaulay faible indique un titre moins sensible. La duration de Macaulay est souvent utilisée pour évaluer le risque de taux d’intérêt et la stratégie de gestion d’un portefeuille d’obligations.\n\n\nFormule\n\\(D = \\frac{\\sum_{t=1}^{n} t \\times CF_t}{\\sum_{t=1}^{n} CF_t}\\)\n(Note: Cette formule est simplifiée et ne prend pas en compte la valeuractualisée des flux de trésorerie. Pour une version plus précise, consultez la formule complète de la duration de Macaulay.)\n\n\nCode\ncash_flows = np.array([10, 10, 110])  # Assuming a bond with 2 annual coupon payments of 10 and a face value of 100\ntime_periods = np.arange(1, len(cash_flows) + 1)\nmacaulay_duration = np.sum(time_periods * cash_flows) / np.sum(cash_flows)\n\nprint(f'Duration de Macaulay: {macaulay_duration:.2f}')\n\n\nDuration de Macaulay: 2.77"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#convexité",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#convexité",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "7. Convexité",
    "text": "7. Convexité\n\nUsage\nLa convexité est utilisée pour mesurer la sensibilité d’un titre à taux fixe, tel qu’une obligation, aux variations des taux d’intérêt, en tenant compte de la courbure de la relation prix-taux d’intérêt.\n\n\nContexte\nUne convexité élevée indique une plus grande sensibilité aux variations des taux d’intérêt, tandis qu’une convexité faible indique une moindre sensibilité. La convexité est souvent utilisée pour évaluer le risque de taux d’intérêt et la stratégie de gestion d’un portefeuille d’obligations.\n\n\nFormule\n\\(C = \\frac{\\sum_{t=1}^{n} t(t+1) \\times CF_t}{(1+y)^t \\times \\sum_{t=1}^{n} CF_t}\\)\n(Note: Cette formule est simplifiée et ne prend pas en compte la valeur actualisée des flux de trésorerie. Pour une version plus précise, consultez la formule complète de la convexité.)\n\n\nCode\ny = 0.03  # Assuming a 3% yield\nconvexity = np.sum(time_periods * (time_periods + 1) * cash_flows) / ((1 + y) ** time_periods * np.sum(cash_flows))\n\n#print(f'Convexité: {convexity:.2f}')"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#valeur-à-risque-var",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#valeur-à-risque-var",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "8. Valeur à Risque (VaR)",
    "text": "8. Valeur à Risque (VaR)\n\nUsage\nLa valeur à risque (VaR) est utilisée pour estimer la perte maximale potentielle d’un portefeuille d’investissement sur une période donnée et à un niveau de confiance donné.\n\n\nContexte\nLa VaR est souvent utilisée pour évaluer le risque de marché et la gestion des risques d’un portefeuille d’investissement.\n\n\nFormule\n\\(VaR = \\mu - z \\times \\sigma\\)\n\n\nCode\nconfidence_level = 0.95\nz = -np.percentile(returns, 100 - (confidence_level * 100))\nvar = -mean_return - z * volatility\n\nprint(f'Valeur à Risque (VaR) à {confidence_level * 100}%: {var:.4f}')\n\n\nValeur à Risque (VaR) à 95.0%: -0.0040"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#value-at-risk-conditionnel-cvar",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#value-at-risk-conditionnel-cvar",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "9. Value at Risk Conditionnel (CVaR)",
    "text": "9. Value at Risk Conditionnel (CVaR)\n\nUsage\nLe CVaR est utilisé pour estimer la perte moyenne potentielle d’un portefeuille d’investissement au-delà de la VaR, sur une période donnée et à un niveau de confiance donné.\n\n\nContexte\nLe CVaR est souvent utilisé pour évaluer le risque de marché et la gestion des risques d’un portefeuille d’investissement, en se concentrant sur les pertes extrêmes.\n\n\nFormule\n\\(CVaR = \\frac{1}{(1 - \\alpha)}\\int_{-\\infty}^{-VaR} xf(x)dx\\)\n\n\nCode\ncvar = -np.mean(returns[returns < -var])\n\nprint(f'Value at Risk Conditionnel (CVaR) à {confidence_level * 100}%: {cvar:.4f}')\n\n\nValue at Risk Conditionnel (CVaR) à 95.0%: 0.0168"
  },
  {
    "objectID": "posts/risk_and_return/10-formules-importantes-finance-marche.html#corrélation",
    "href": "posts/risk_and_return/10-formules-importantes-finance-marche.html#corrélation",
    "title": "10 formules les plus utilisées en finance de marché",
    "section": "10. Corrélation",
    "text": "10. Corrélation\n\nUsage\nLa corrélation est utilisée pour mesurer la relation entre les rendements de deux actifs financiers.\n\n\nContexte\nUne corrélation positive indique que les rendements de deux actifs évoluent généralement dans la même direction, tandis qu’une corrélation négative indique qu’ils évoluent généralement dans des directions opposées. La corrélation est souvent utilisée pour évaluer la diversification d’un portefeuille d’investissement.\n\n\nFormule\n\\(\\rho = \\frac{\\mathrm{Cov}(R_i, R_j)}{\\sigma_i \\sigma_j}\\)\n\n\nCode\nticker_2 = 'MSFT'\ndata_2 = yf.download(ticker_2, start='2020-01-01', end='2021-01-01')['Adj Close']\nreturns_2 = data_2.pct_change().dropna()\n\ncorrelation_matrix = np.corrcoef(returns, returns_2)\ncorrelation = correlation_matrix[0][1]\n\nprint(f'Corrélation entre {ticker} et {ticker_2}: {correlation:.4f}')\n\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nCorrélation entre AAPL et MSFT: 0.8393\n\n\nCes 10 formules sont essentielles pour comprendre et analyser les actifs financiers et les portefeuilles d’investissement en finance de marché. En utilisant ces formules et les outils Python tels que yfinance et matplotlib, vous pouvez facilement récupérer des données de marché et visualiser les résultats de vos analyses."
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#introduction",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#introduction",
    "title": "Portfolio optimisation with Python",
    "section": "Introduction",
    "text": "Introduction\nHarry Markowitz is one of the (if not “the”) fathers of modern portfolio construction and his seminal paper Portfolio Selection{% fn 1 %} has driven an entire research stream.\nThe intuition behind this paper is that one can combine the information gathered on expected returns, risks and diversification of various assets or asset classes with a view to optimise the risk-return profile of a given portfolio.\nIn practice, we typically find a limited stability of the portfolios generated using this approach, especially due the high sensitivity of the portfolio to the expected returns; nonetheless, the insights it provides are very useful and it’s a perfect start to see the impact of risk and diversification.\nFor this article, we will mostly rely on a fantastic Python library, PyPortfolioOpt {% fn 2%} which will do the optimisation heavy lifting for us."
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#setup",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#setup",
    "title": "Portfolio optimisation with Python",
    "section": "Setup",
    "text": "Setup\n\nLoading Libraries\nThe main library to load here is indeed PyPortfolioOpt{% fn 2%}, and we will rely extensively on it in this article.\nWe need the following tools as well: - Pandas{% fn 3%}: load, filter, sort and pretty much all data wrangling operations; - Numpy{% fn 4%}: provides most matrix and advanced numerical operations; this library is the calculation backbone for pandas; - Matplotlib{% fn 5%}: the de facto reference library to draw scientific charts; - yfinance{% fn 6%}: a very handy library to access many different online databases, including Yahoo Finance.\n\n\nCode\n#collapse-hide\nimport numpy as np \nimport pandas_datareader.data as web_reader\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport yfinance as yf\n\nfrom pypfopt.efficient_frontier import EfficientFrontier\nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns\n\n\n\n\nMisc Parameters\nIn the code below, we set some variables to adjust the jupyter loo\n\n\nCode\n#collapse-hide\n# Note that this change the decimals places inside Jupyter, but not on the website\npd.options.display.float_format = '{:,.1f}'.format"
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#defining-our-investable-universe",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#defining-our-investable-universe",
    "title": "Portfolio optimisation with Python",
    "section": "Defining our Investable Universe",
    "text": "Defining our Investable Universe\nFirst and foremost, we need to define our Investable Universe i.e. the set of asset classes that we will allow in our portfolio.\nMany investors would typically think about single stocks, but on my side, I am typically looking I am looking here a Long Term Investing, and I would be keen to\nSpeaking about asset classes, we need some ETFs to analyse!\n\n“Important: Please bear in mind this article if purely for pedagogical purpose and should by no mean be understood as a recommendation or advice. Investing brings risk and in particular risk of loss of capital. I have no intention to recommend anything! I will follow among others this recent article in US News{% fn 7%} and ETF.com{% fn 8%} as sources of inspiration to identify relevant ETFs.”\n\n\nEquity\nLet’s start with various Equity sub-asset classes:\n\nIVV: iShares Core S&P 500 ETF representing US Equity Large Cap\nSCHA: Schwab U.S. Small-Cap ETF representing US Equity Small Cap\nIJH: iShares Core S&P Mid-Cap ETF representing US Equity Mid Cap\nSCHD: Schwab U.S. Dividend Equity ETF representing US Equity Dividend (ie US stocks which are deemed to pay higher dividends)\nVTI: Vanguard Total Stock Market ETF representing US Equity, with all market cap included\nVXUS: Vanguard Total International Stock ETF representing World ex-US equities\nEEM: iShares MSCI Emerging Markets ETF representing the Emerging Market Equities\n\n\n\nFixed Income\nLet’s add Fixed Income, which would typically aim to reduce the overall portfolio’s volatility:\n\nAGG: iShares Core U.S. Aggregate Bond ETFrepresenting the entire US Bond market\nGOVT: iShares U.S. Treasury Bond ETF representing the performance of US Government Bonds\nVCLT: Vanguard Long-Term Corporate Bond ETF representing the Investment Grade USD denominated bonds.\n\n\n\nAlternative Assets\nLet’s add 2 additional asset classes, Gold and Commodities: - GLD: SPDR Gold Trust representing the price of Gold - PDBC: Invesco Optimum Yield Diversified Commodity** Strategy No K-1 ETF** which will represent the performance of the Broad Commodities asset class\nEverything in the above is denominated in US Dollars, this will make our life easier in what follows, ie we will not need any currency conversion, which is always a bit painfull in the process."
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#parameters-and-data-gathering",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#parameters-and-data-gathering",
    "title": "Portfolio optimisation with Python",
    "section": "Parameters and data gathering",
    "text": "Parameters and data gathering\nI recommend you to read this article about data gathering.\nLike we did in this article, we will utilise pandas_datareader{% fn 6%} to get historical time series. As mentioned above, we will look at the performance of ETFs, which we will consider as as relevant proxies for their respective asset classes.\nYou can of course utilise whatever asset class you want, and take single stocks, funds as historical data points. On my side, I am quite familiar with indices ETFs, and I will go with the selection above.\nLast but not least, we need to define the start_date and end_date for gathering the historical time series. For this study, we will gather 7 years of data.\n\n\nCode\n#collapse-hide\n\nstart_date = '2015-03-01'\nend_date = '2022-03-01'\n\n# Define Investable Universe\ninvestable_universe_tickers = ['IVV', 'SCHA', 'IJH', 'SCHD', 'VTI', 'VXUS', 'EEM', 'VCLT', 'AGG', 'GOVT','PDBC','GLD']\n\n# Get Historical Data\ndf = yf.download(investable_universe_tickers, start=start_date, end=end_date)\ndf = df['Adj Close']\n\n# This is required to round the blog's table into 2 decimals, Jupyter's formatting does not apply on the published website\ndf = df.round(decimals=1)\n\n\n[                       0%                       ][                       0%                       ]\n\n\n[************          25%                       ]  3 of 12 completed[************          25%                       ]  3 of 12 completed\n\n\n[********************  42%                       ]  5 of 12 completed[********************  42%                       ]  5 of 12 completed\n\n\n[********************  42%                       ]  5 of 12 completed\n\n\n[**********************67%*******                ]  8 of 12 completed\n\n\n[**********************67%*******                ]  8 of 12 completed\n\n\n[**********************83%***************        ]  10 of 12 completed\n\n\n[**********************83%***************        ]  10 of 12 completed\n\n\n[*********************100%***********************]  12 of 12 completed\n\n\n\n\n\n\nData gathering: results\nThe request above delivered a pandas data_frame, and here is a snapshot of the last 5 rows:\n\n\nCode\n#collapse-hide\ndf.tail(3)\n\n\n\n\n\n\n  \n    \n      \n      AGG\n      EEM\n      GLD\n      GOVT\n      IJH\n      IVV\n      PDBC\n      SCHA\n      SCHD\n      VCLT\n      VTI\n      VXUS\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2022-02-24\n      106.4\n      45.4\n      177.1\n      25.0\n      253.0\n      421.6\n      14.3\n      45.0\n      72.0\n      90.5\n      212.3\n      57.5\n    \n    \n      2022-02-25\n      106.5\n      46.2\n      176.6\n      25.0\n      260.3\n      430.9\n      14.0\n      46.1\n      74.2\n      91.0\n      217.0\n      58.8\n    \n    \n      2022-02-28\n      107.2\n      45.6\n      178.4\n      25.2\n      260.3\n      430.0\n      14.3\n      46.3\n      73.9\n      92.4\n      216.8\n      58.0\n    \n  \n\n\n\n\n\n\nNormalisation\nA table like the above is not very useful: in the absence a of particle knowledge of the ETFs’ values, we have no way of knowing if a value is “high” or “low”, hence apart from telling us that the value is a number we have now way to let’s try to make this table a bit more insightful.\nThe request above delivered a data_frame, and here is a snapshot of the last 5 rows:\n\n\nCode\n#collapse-hide\n# Same table, but this time, normalised\n(df/df.iloc[0, ]*100).round(decimals=1).tail(3)\n\n\n\n\n\n\n  \n    \n      \n      AGG\n      EEM\n      GLD\n      GOVT\n      IJH\n      IVV\n      PDBC\n      SCHA\n      SCHD\n      VCLT\n      VTI\n      VXUS\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2022-02-24\n      116.9\n      132.4\n      153.1\n      112.6\n      189.5\n      229.6\n      136.2\n      175.8\n      228.6\n      135.1\n      224.2\n      141.6\n    \n    \n      2022-02-25\n      117.0\n      134.7\n      152.6\n      112.6\n      195.0\n      234.7\n      133.3\n      180.1\n      235.6\n      135.8\n      229.1\n      144.8\n    \n    \n      2022-02-28\n      117.8\n      132.9\n      154.2\n      113.5\n      195.0\n      234.2\n      136.2\n      180.9\n      234.6\n      137.9\n      228.9\n      142.9\n    \n  \n\n\n\n\nThis is much better.\nNow we can at least see that: - US Equities (e.g. IVV) had a fantastic ride since 2015; - Government bonds (e.g. GOVT) under-performed; - Commodities (PDBC) and Gold (GLD) had several rough years as well, with recent massive pick-up in the current geopolitical context.\n\n\nVisualise asset classes’ returns\nBeing able to sanity check the data is very important, and it’s often more efficient with a quick chart.\n\n\nCode\n#collapse-hide\n\n# Normalise to 100\nnormalised_data = (df/df.iloc[0, ]*100)\n\n# A bit of data wrangling\ntransposed_data = normalised_data.tail(1).reset_index().transpose()\ntransposed_data = transposed_data.iloc[1:len(transposed_data)]\ntransposed_data = transposed_data.rename(columns={0: \"Last Value\"})\n\n# We want a bar chart sorted by decreaseing values\ntransposed_data = transposed_data.sort_values(by=\"Last Value\", ascending=False)\n\n# Theming Seaborn results\nsns.set_theme()\n\n# Draw\ntransposed_data.plot.bar(figsize=(10, 6))\npass\n\n\n\n\n\n\n\nDraw the wealth curve\nThe table above is useful, but when it comes to grasping and long term risks and returns, a chart is worth a thousand words.\nA very common issue when charting multiple time series is the very different stock levels, and this can make the chart hard to read.\nThis is why we will once again normalise the data.\n\n\nCode\n#collapse-hide\n\n# Theming Seaborn results\nsns.set_theme()\n\n# Plot the time series\nplt.figure(figsize=(12,6))\n\n# Legends and Axis titles\np = sns.lineplot(data=normalised_data)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#estimate-risk-and-return",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#estimate-risk-and-return",
    "title": "Portfolio optimisation with Python",
    "section": "Estimate risk and return",
    "text": "Estimate risk and return\nIn Markowitz 1952{% fn 1 %}, the optimal portfolio is obtained as a function of expected returns and expected risks of the portfolio. This takes a strong assumption that we have a “crystal ball”, or at least access to a predictive model, which at this stage is well beyond this article.\nFor this first example, we will rely on historical parameters estimation, which precisely means that we expect the past to be a good prediction of what might happen in the future.\n\nVolatility\nThere are many ways to estimate the volatility, and I will only cover the simplest approach.\nWe have access to daily close prices of the ETFs, hence we could look at the standard deviation of daily returns. In theory this would utilise most of the data we have access to, which is a good thing. In practice, and especially when looking at asset classes which can be observed with an 8 to 12 hours time difference which might lead the “sample volatility” to become inconsistent between 2 asset classes. This is even more important for estimating the correlation.\nPractitioners often use weekly returns to alleviate this issue, and we will do the same here, and as such calculate the returns using a resampled time series. To calculate the annualized volatility requires an additional factor in this case the square root of 52. Why this?\nVolatility is essential to option traders, and when pricing options, practitioners often model asset prices as Wiener processes(number of weeks in a year) {% fn 9 %}. The variance of a Wiener process is proportional to the time, and the volatility is the square root of the the variance, which gives us that to convert standard deviation of weekly returns into an annualized figure, we need to multiply our results by the square root of the number of weeks in a year (more on Wiener processes here {% fn 9 %}).\n\n\nCode\nweekly_returns = df.resample(\"W\").last().pct_change()\n((weekly_returns.std()*math.sqrt(52)*100).sort_values()).plot.bar();\n\n\n\n\n\nAs one could have guessed, on the left of the chart above, we can find the low volatility asset classes (e.g. Government Bonds, Investment Grade Bonds), whereas on the right we have high volatility asset classes (Mid Cap and Small Cap Equities)."
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#correlation",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#correlation",
    "title": "Portfolio optimisation with Python",
    "section": "Correlation",
    "text": "Correlation\n\n\nCode\nsns.heatmap(weekly_returns.corr());\n\n\n\n\n\n\n\nCode\n#collapse-hide\nfrom pypfopt import risk_models\nfrom pypfopt import plotting\n\n# Calculate expected returns and sample covariance\nmu = expected_returns.mean_historical_return(df)\nsample_cov = risk_models.sample_cov(df, frequency=252)\n\nS = risk_models.CovarianceShrinkage(df).ledoit_wolf()"
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#the-main-results-efficient-frontier-maximum-sharpe-portfolio",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#the-main-results-efficient-frontier-maximum-sharpe-portfolio",
    "title": "Portfolio optimisation with Python",
    "section": "The main results: Efficient Frontier & Maximum Sharpe Portfolio",
    "text": "The main results: Efficient Frontier & Maximum Sharpe Portfolio\n\nCalculate and draw the efficient frontier\nWith expected returns and risk estimated, we are ready to utilise PyPortfolioOpt’s optimiser to draw the efficient frontier.\nThe idea behind the efficient frontier{% fn 1 %} is relatively simple: - For each level of investor’s risk, there is an optimal portfolio which is expected to deliver the highest level of return; or conversely - For each level of investor’s return, there is an optimal portfolio which is expected to deliver the lowest level of return.\n\n\nCode\n#collapse-hide\nef = EfficientFrontier(mu, sample_cov)\n\n# We create 2 efficient frontiers\nfig, ax = plt.subplots()\nplotting.plot_efficient_frontier(ef, ax=ax, show_assets=True)\nax.set_title(\"Asset Classes & Efficient Frontier\")\n\nplt.show()\n\n\n\n\n\n\n\nAdd the Maximum Sharpe portfolio\n\n\nCode\n#collapse-hide\n\n# Find and plot the tangency portfolio\nfig2, ax = plt.subplots()\nef2 = EfficientFrontier(mu, S) \nplotting.plot_efficient_frontier(ef2, ax=ax, show_assets=True)\n\nef3 = EfficientFrontier(mu, S) \n\nef3.max_sharpe()\nret_tangent, std_tangent, _ = ef3.portfolio_performance()\nax.scatter(std_tangent, ret_tangent, marker=\"*\", s=100, c=\"r\", label=\"Max Sharpe\")\nax.set_title(\"Asset Classes, Efficient Frontier & Max Sharpe portfolio\")\nplt.show()\n\n\n\n\n\n\n\nCalculate random portfolios\n\n\nCode\n#collapse-hide\n\n# Plot random portfolios\nfig2, ax = plt.subplots()\nn_samples = 10000\nw = np.random.dirichlet(np.ones(len(mu)), n_samples)\nrets = w.dot(mu)\nstds = np.sqrt((w.T * (S @ w.T)).sum(axis=0))\nsharpes = rets / stds\nax.scatter(stds, rets, marker=\".\", c=sharpes, cmap=\"viridis_r\")\n\n# Format\nax.set_title(\"Random portfolios, based on the same asset classes\")\n#ax.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#conclusion",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#conclusion",
    "title": "Portfolio optimisation with Python",
    "section": "Conclusion",
    "text": "Conclusion\nEt voila!\nCompared to macros or Excel formulas, this is an amazing improvement, and enables us to customise everything in seconds: historical timeframe, asset classes, etc.\nTo deliver a full portfolio optimisation process in such a limited number of lines is truly awesome.\nI hope this article provided you some ideas on how to look at portfolio construction.\nHappy coding, and happy portfolio construction!\n{% series_list %}"
  },
  {
    "objectID": "posts/risk_and_return/optimise-portfolios-with-python.html#resources",
    "href": "posts/risk_and_return/optimise-portfolios-with-python.html#resources",
    "title": "Portfolio optimisation with Python",
    "section": "Resources",
    "text": "Resources\n{{ ‘Portfolio Selection, Henri Markowitz, 1952’ | fndetail: 1 }}\n{{ ‘PyportfolioOpt, Robert Andrew Martin, 2018’ | fndetail: 2}}\n{{ ‘Pandas’ | fndetail: 3 }}\n{{ ‘Numpy’ | fndetail: 4 }}\n{{ ‘Matplolib’ | fndetail: 5}}\n{{ ‘Pandas_datareader’ | fndetail: 6}}\n{{ ‘US News, 7 Best Long-Term ETFs to Buy and Hold, 25 Feb 2022’ | fndetail: 7}}\n{{ ‘ETF.com’ | fndetail: 8}}\n{{ ‘Wikipedia.com / Wiener Processes’ | fndetail: 9}}"
  },
  {
    "objectID": "posts/risk_and_return/estimating_risk.html",
    "href": "posts/risk_and_return/estimating_risk.html",
    "title": "Getting Started: measuring volatility",
    "section": "",
    "text": "Code\nimport pandas\n\n\n # Getting Started: Measuring Volatility"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#introduction",
    "href": "posts/publication-workflow/visualizing-historical-data.html#introduction",
    "title": "Visualising Historical Data",
    "section": "Introduction",
    "text": "Introduction\nTo start our data analysis and portfolio construction journey, we will perform the basic - but essential - task of getting access to time series and plot them using pandas.\n\nTip: This article is written as a Jupyter Notebook. It has been published using Fastpages. The Jupyter notebook is available on GitHub and if you want to, you can run it directly using the provided Binder link displayed at the top of the article."
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#load-libraries",
    "href": "posts/publication-workflow/visualizing-historical-data.html#load-libraries",
    "title": "Visualising Historical Data",
    "section": "Load libraries",
    "text": "Load libraries\nA key benefit of Python is the sheer number of libraries we can leverage to perform a particular task. Choosing the right library might look a bit overwhelming, and one the goals of this blog is actually to provide the reader my honest view on what makes most sense to perform the usual tasks in my daily work.\nThe key module for this article is yfinance, a fantastic data gathering library that you can find here on GitHub.\n\n\nCode\n#collapse-hide\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport yfinance as yf\nimport datetime as dt\n\n# Note that this change the decimals places inside Jupyter, but not on the website\npd.options.display.float_format = '{:,.1f}'.format"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#get-historical-data",
    "href": "posts/publication-workflow/visualizing-historical-data.html#get-historical-data",
    "title": "Visualising Historical Data",
    "section": "Get historical data",
    "text": "Get historical data\nLet’s get ready, and gather some historical data for, say, 4 Exchange Traded Funds (ie “ETFs”, still commonly referred to as “trackers” in France): - SPY: S&P 500 - GLD: Gold - AGG: US Aggregate (US Bonds) - CAC.PA: CAC 40 (French Equity Index)\nYou might wonder what the first 3 letters actually correspond to? They are the usual identifier for each ETF on the markets, and are often called the tickerof the ETF.\nTo gather data, you must de facto provide one ticker for each security, but if you forgot the ticker, Google is usually your friend!\nWe will need define to find a few more parameters: - The 2 variables start_date and end_date to keep some flexibility, - The variable tickers will store our ticker list, and pass it as a parameter to Yahoo, in order to specify our query.\n\n\nCode\n#collapse-hide\n\nstart_date = '2015-01-01'\nend_date = '2022-05-14'\ntickers = ['SPY', 'GLD', 'AGG', 'CAC.PA']\ndf = yf.download(tickers,  start=start_date, end=end_date)\n\n# This ones keep the decimals to one on the website. \n# This is especially useful to print dataframes.\ndf = df.round(decimals=2)\n\n\n\n[                       0%                       ]\n\n\n[                       0%                       ][                       0%                       ]\n\n\n[*********************100%***********************]  4 of 4 completed"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#visual-data-check",
    "href": "posts/publication-workflow/visualizing-historical-data.html#visual-data-check",
    "title": "Visualising Historical Data",
    "section": "Visual data check",
    "text": "Visual data check\nBy default, Yahoo Finance provides us with several fields, not all of them will be useful in this introduction, and we will perform some further filtering below.\nTo quickly check the status of what we now have, note the use of the tail() function below.\nPandas tail() function\n\n\nCode\ndf.tail(3)\n\n\n\n\n\n\n  \n    \n      \n      Adj Close\n      Close\n      High\n      ...\n      Low\n      Open\n      Volume\n    \n    \n      \n      AGG\n      CAC.PA\n      GLD\n      SPY\n      AGG\n      CAC.PA\n      GLD\n      SPY\n      AGG\n      CAC.PA\n      ...\n      GLD\n      SPY\n      AGG\n      CAC.PA\n      GLD\n      SPY\n      AGG\n      CAC.PA\n      GLD\n      SPY\n    \n    \n      Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2022-05-11\n      100.3\n      62.6\n      172.8\n      386.2\n      102.8\n      62.6\n      172.8\n      392.8\n      102.8\n      62.6\n      ...\n      172.2\n      392.0\n      102.1\n      61.7\n      172.5\n      398.1\n      16,462,000.0\n      45,387.0\n      9,179,600.0\n      142,361,000.0\n    \n    \n      2022-05-12\n      100.5\n      62.0\n      170.2\n      385.8\n      103.0\n      62.0\n      170.2\n      392.3\n      103.1\n      62.3\n      ...\n      169.9\n      385.1\n      102.9\n      61.4\n      172.1\n      389.4\n      9,015,300.0\n      62,497.0\n      11,626,800.0\n      125,090,800.0\n    \n    \n      2022-05-13\n      100.1\n      63.5\n      168.8\n      395.0\n      102.5\n      63.5\n      168.8\n      401.7\n      102.8\n      63.5\n      ...\n      168.0\n      395.6\n      102.8\n      62.4\n      168.3\n      396.7\n      6,715,600.0\n      77,603.0\n      13,031,100.0\n      104,174,400.0\n    \n  \n\n3 rows × 24 columns\n\n\n\nThe Adjusted Close field is returned by Yahoo Finance and is exactly what we are looking for.\nAdjusted Close corresponds to the time series containing what we usually call the total return, typically compounding the dividends with the price returns.\nThis reflects the total return delivered by the ETF, should the investor reinvest systematically the dividend paid by the ETF by buying more this ETF. This is probably the most useful field when we aim to assess the long term returns of an asset class.\nTo quickly check the status of what we now have, note the use of the tail() function below, which get the last n rows of the dataset. Combined with Jupyter’s power in printing data, it’s probably the fastest way to navigate and check a particular dataset.\nPandas tail() function\n\n\nCode\ndf['Adj Close'].tail(3)\n\n\n\n\n\n\n  \n    \n      \n      AGG\n      CAC.PA\n      GLD\n      SPY\n    \n    \n      Date\n      \n      \n      \n      \n    \n  \n  \n    \n      2022-05-11\n      100.3\n      62.6\n      172.8\n      386.2\n    \n    \n      2022-05-12\n      100.5\n      62.0\n      170.2\n      385.8\n    \n    \n      2022-05-13\n      100.1\n      63.5\n      168.8\n      395.0"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#plot-the-raw-time-series-using-the-seaborn-library",
    "href": "posts/publication-workflow/visualizing-historical-data.html#plot-the-raw-time-series-using-the-seaborn-library",
    "title": "Visualising Historical Data",
    "section": "Plot the raw time series using the seaborn library",
    "text": "Plot the raw time series using the seaborn library\nTo quickly check that we got the right data, let’s visualise it.\n\n\nCode\n#collapse-hide\nimport seaborn as sns\n\n# Apply the default theme\nsns.set_style('whitegrid')\n\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=df['Adj Close'])\np.set_ylabel(\"Close Price\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#plot-the-normalised-the-time-series",
    "href": "posts/publication-workflow/visualizing-historical-data.html#plot-the-normalised-the-time-series",
    "title": "Visualising Historical Data",
    "section": "Plot the normalised the time series",
    "text": "Plot the normalised the time series\nThe chart above is useful, but the vast difference between the ETFs’ values makes it a bit hard to actually track each respective time series.\nIt would be more effective to normalise the data. It’s often referred to as “rebasing”, ie making each time series starting at 100, this will make it much easier to compare.\n\n\nCode\n#collapse-hide\n\n# Normalise the data, which here means for each column to start at 100, with subsequent price development \"scaled\" according to daily returns\nnormalised_ts = (df['Adj Close']/df['Adj Close'].iloc[0, ]*100)\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=normalised_ts)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#rolling-window-cumulated-returns",
    "href": "posts/publication-workflow/visualizing-historical-data.html#rolling-window-cumulated-returns",
    "title": "Visualising Historical Data",
    "section": "Rolling window cumulated returns",
    "text": "Rolling window cumulated returns\nIt’s often easy to get ‘seduced’ by the compelling long term returns, especially about Equities. And indeed, it was a good thing to be invested in Equities in the long run !\nBut 1y returns are usually a good way to keep track of the portfolio, and moreover to see how these returns have developed over time. With a 1y return chart, the notion of risk, ie either fast-changing returns, or - even worse - consistently negative returns, quickly becomes apparent.\n\n\nCode\n# We use pct_change() to calculate the one year return\nts_1y_returns = df['Adj Close'].pct_change(periods=252)\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=ts_1y_returns)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#smoother-returns",
    "href": "posts/publication-workflow/visualizing-historical-data.html#smoother-returns",
    "title": "Visualising Historical Data",
    "section": "Smoother returns",
    "text": "Smoother returns\nThe chart above is great, but a bit too busy for my taste. Whilst accurate, there is too much info going on, the noise might reduce our ability to spot real medium terms or breakouts.\nThis is where pandas starts to be really powerful. The rolling() function essentially captures sub-series, with a defined length (here 21 days). By chaining the results of rolling() with the mean function, ie calculating the arithmetic average, this will provide us in a one-liner with a new series. This generated dataframe contains the time series of the moving average (21 days) for each of our time series.\nWhilst this “chaining” approach might initially sound obscure, this is extremely powerful, especially when factoring in the fact that you just need to change the tickers of the ETFs in the beginning of the article to entirely update the whole analysis … your turn!\n\n\nCode\n# Normalise the data, which here means for each column to start at 100, with subsequent price development \"scaled\" according to daily returns\nts_1y_returns = df['Adj Close'].pct_change(periods=252).rolling(window=21).mean()\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=ts_1y_returns)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass"
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#conclusion",
    "href": "posts/publication-workflow/visualizing-historical-data.html#conclusion",
    "title": "Visualising Historical Data",
    "section": "Conclusion",
    "text": "Conclusion\nSo that’s it for this short intro on data gathering and visualising. In this article, we have gathered, checked, normalised and plot close prices for different ETFs.\nThe next step will be to use these function to generate some returns and risk statistics, and start exploring portfolio construction.\nSee you in the next article, and stay safe."
  },
  {
    "objectID": "posts/publication-workflow/visualizing-historical-data.html#useful-related-links",
    "href": "posts/publication-workflow/visualizing-historical-data.html#useful-related-links",
    "title": "Visualising Historical Data",
    "section": "Useful Related Links",
    "text": "Useful Related Links\n{% series_list %}\nThere is no such thing as “full tutorial on something”, knowledge is everywhere. I found these tutorials pretty handy, check them out too!\n\nSeaborn Tutorial\nTutorial on F-Strings"
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#le-price-to-earnings-ratio-per",
    "href": "posts/tutorials/fr/valorisation-pe.html#le-price-to-earnings-ratio-per",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Le Price to Earnings Ratio (“PER”)",
    "text": "Le Price to Earnings Ratio (“PER”)\nLe Price to Earnings Ratio (PER) est un ratio financier utilisé pour évaluer la valorisation d’une action par rapport à ses bénéfices. Il est calculé en divisant le prix actuel de l’action par le bénéfice par action (EPS) sur une période donnée, généralement sur les 12 derniers mois. La formule est la suivante :\n\\[\nPER = \\frac{Prix\\ de\\ l'action}{Bénéfice\\ par\\ action}\n\\]\nUn PER élevé indique que les investisseurs sont prêts à payer davantage pour les bénéfices futurs de l’entreprise, tandis qu’un PER faible suggère que les investisseurs estiment que l’action est sous-évaluée ou que l’entreprise a des perspectives de croissance limitées."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#la-librairie-alpha-vantage",
    "href": "posts/tutorials/fr/valorisation-pe.html#la-librairie-alpha-vantage",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "La librairie Alpha Vantage",
    "text": "La librairie Alpha Vantage\nAlpha Vantage est une plateforme de données financières qui fournit des API pour accéder à diverses informations sur le marché, telles que les cours des actions, les indicateurs techniques, les données sur les devises, les cryptomonnaies et bien d’autres. La librairie Python alpha_vantage permet d’interagir facilement avec ces API.\nLa licence gratuite d’Alpha Vantage permet d’accéder à la plupart des données sans frais. Toutefois, elle est soumise à certaines restrictions, notamment un nombre limité de requêtes par minute et par jour. Pour des usages plus intensifs, des plans payants sont disponibles."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#code-source",
    "href": "posts/tutorials/fr/valorisation-pe.html#code-source",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Code Source",
    "text": "Code Source\nVoici un exemple de programme Python qui utilise la bibliothèque yfinance pour récupérer les valorisations des ETFs secteurs en Europe. Dans cet exemple, je vais utiliser quelques ETFs populaires en Europe pour illustrer le processus. Vous pouvez ajouter ou modifier les symboles d’ETFs dans la liste etfs pour récupérer les valorisations des ETFs que vous souhaitez.\n\n\nCode\nimport os, sys\nroot_path = os.path.join(sys.path[0],'..','..', '..')\nsys.path.append(root_path)\nimport blog_utils\n\ntpl_path = \"https://github.com/vdenoise/templates/raw/master\"\nmpl_tpl_path = f\"{tpl_path}/matplotlib\"\n\n\n\n\nCode\n\nimport keyring\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom alpha_vantage.fundamentaldata import FundamentalData\n\n# Remplacez 'your_api_key' par votre clé API Alpha Vantage\napi_key = keyring.get_password(\"alpha_vantage_api_key\", \"email@email.com\")\nfd = FundamentalData(key=api_key)\n\n# Fonction pour récupérer le Price to Earnings Ratio (P/E Ratio)\ndef get_price_to_earnings_ratio(symbol):\n    data, _ = fd.get_company_overview(symbol)\n    pe_ratio = float(data[\"PERatio\"])\n    return pe_ratio\n\n# Récupérer et afficher les P/E Ratios\nsymbols = [\"AAPL\", \"MSFT\", \"IBM\"]\npe_ratios = [get_price_to_earnings_ratio(symbol) for symbol in symbols]\n\nmatplotlib.rcdefaults() \nblog_utils.apply_right_style()\nplt.bar(symbols, pe_ratios)\nplt.xlabel(\"Symboles\")\nplt.ylabel(\"Price to Earnings Ratio\")\nplt.title(\"Comparaison des PER de différentes actions\")\nplt.show()\n\n\n\nNone\n\n\n\n\n\nNotez que les tickers d’ETFs dans etf_tickers sont des exemples. Vous devrez remplacer cette liste par les tickers des ETFs de secteurs en Europe que vous souhaitez analyser. Ce programme récupère le P/E Ratio pour chaque ETF et affiche les résultats à l’écran."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#conclusion",
    "href": "posts/tutorials/fr/valorisation-pe.html#conclusion",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Conclusion",
    "text": "Conclusion\nEn résumé, dans cet article tres court, nous avons montré comment récupérer le Price to Earnings Ratio (PER) de plusieurs actions en utilisant Python, la librairie Alpha Vantage et la bibliothèque de visualisation de données Matplotlib. Le PER est un indicateur financier clé pour évaluer la valorisation d’une action et comparer différentes entreprises."
  },
  {
    "objectID": "posts/tutorials/fr/valorisation-pe.html#sources-de-référence",
    "href": "posts/tutorials/fr/valorisation-pe.html#sources-de-référence",
    "title": "Obtenir la valorisation de plusieurs titres avec Python et Alpha Vantage",
    "section": "Sources de référence",
    "text": "Sources de référence\nPour en savoir plus sur Alpha Vantage, la valorisation des actions et l’utilisation du Price to Earnings Ratio dans l’analyse financière, consultez les sources suivantes :\n\nSite officiel d’AlphaVantage : https://www.alphavantage.co/\nDocumentation de la librairie Python alpha_vantage : https://alpha-vantage.readthedocs.io/\nInvestopedia, “Price-to-Earnings Ratio – P/E Ratio” : https://www.investopedia.com/terms/p/price-earningsratio.asp\nCorporate Finance Institute, “Price Earnings Ratio (P/E Ratio)” : https://corporatefinanceinstitute.com/resources/knowledge/valuation/price-earnings-ratio/\nMatplotlib, documentation officielle : https://matplotlib.org/"
  },
  {
    "objectID": "posts/tutorials/en/getting-started-with-eurostat-api.html",
    "href": "posts/tutorials/en/getting-started-with-eurostat-api.html",
    "title": "Getting Started with Eurostat API",
    "section": "",
    "text": "# Connect to Eurostat API with Python using their REST API\nEurostat, the statistical office of the European Union, provides access to a wealth of data on various aspects of the European economy, environment, and society. One way to access this data is through their REST API, which can be easily connected to and queried using Python.\nIn this article, we will walk you through the steps needed to connect to the Eurostat API using Python and build a function to show the connection status to the API. By the end, you’ll be able to retrieve data from Eurostat in a structured and efficient manner."
  },
  {
    "objectID": "posts/tutorials/en/getting-started-with-eurostat-api.html#prerequisites",
    "href": "posts/tutorials/en/getting-started-with-eurostat-api.html#prerequisites",
    "title": "Getting Started with Eurostat API",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore we begin, make sure you have Python installed on your system. You can check whether you have Python installed and which version you’re using by running the following command in your terminal:\npython --version\nIf you don’t have Python installed, you can download it from the official Python website.\nNext, you will need to install the requests library, which allows you to make HTTP requests in Python. To do this, open your terminal and run:\npip install requests"
  },
  {
    "objectID": "posts/tutorials/en/getting-started-with-eurostat-api.html#connecting-to-the-eurostat-api",
    "href": "posts/tutorials/en/getting-started-with-eurostat-api.html#connecting-to-the-eurostat-api",
    "title": "Getting Started with Eurostat API",
    "section": "Connecting to the Eurostat API",
    "text": "Connecting to the Eurostat API\nTo connect to the Eurostat API, you need to send HTTP requests to their API endpoints. The base URL for the Eurostat API is:\nhttps://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/\nYou can append the relevant endpoint to this base URL to access specific datasets or services.\nFor example, to access the dataset on GDP per capita, you would send a request to:\nhttps://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/nama_10_pc?format=sdmx-compact-2.1\nHere’s a Python function that sends a request to the Eurostat API and checks the connection status:\n\n\nCode\nimport requests\n\ndef check_connection_status(endpoint):\n    response = requests.get(endpoint)\n    status_code = response.status_code\n    \n    if status_code == 200:\n        print(\"Connection Successful! (Status Code: 200)\")\n    elif status_code == 404:\n        print(\"Error: Dataset not found (Status Code: 404)\")\n    else:\n        print(f\"Error: Connection failed (Status Code: {status_code})\")\n\n# Test the function with the base URL\napi_base_url = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/sdmx-rest.wadl\"\ncheck_connection_status(api_base_url)\n\n\nConnection Successful! (Status Code: 200)\n\n\nThis function sends an HTTP GET request to the specified api_url and checks the response’s status code. If the status code is 200, the connection is successful. If the status code is anything other than 200, the connection has failed, and the function raises an exception with the corresponding error message.\nTo use this function, replace api_url with the desired Eurostat API endpoint."
  },
  {
    "objectID": "posts/tutorials/en/getting-started-with-eurostat-api.html#conclusion",
    "href": "posts/tutorials/en/getting-started-with-eurostat-api.html#conclusion",
    "title": "Getting Started with Eurostat API",
    "section": "Conclusion",
    "text": "Conclusion\nIn this article, we demonstrated how to connect to the Eurostat API using Python and their REST API. We also showed you how to create a simple function to check the connection status to the API.\nWith these tools in hand, you can now access a wide variety of European statistical data and use it in your data analysis or visualization projects. Happy coding!"
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#introduction",
    "href": "posts/tutorials/en/shiller-data-python.html#introduction",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Introduction",
    "text": "Introduction\nIn this article, we will explore how to download Shiller’s Excel data on long-term stock market returns from his website using Python. We will use the requests library for HTTP requests and the pandas library for data manipulation. For visualization, we will use the Matplotlib library with the Pacoty stylesheet to create a chart comparing nominal equity returns, real equity returns, and real GDP growth.\nDownloading Shiller’s Data\nFirst, we need to import the required libraries and download the data using an HTTP request:\nThis code snippet downloads the Excel file from Shiller’s website and reads it into a pandas DataFrame.\n\n\nCode\nimport requests\nimport pandas as pd\nfrom io import BytesIO\n\nurl = \"http://www.econ.yale.edu/~shiller/data/ie_data.xls\"\n\nresponse = requests.get(url)\n\n# Check if the request was successful\nif response.status_code == 200:\n    data = pd.read_excel(BytesIO(response.content), sheet_name='Data', header=7)\nelse:\n    print(\"Failed to download the data\")"
  },
  {
    "objectID": "posts/tutorials/en/shiller-data-python.html#visualizing-the-data-with-matplotlib-and-pacoty",
    "href": "posts/tutorials/en/shiller-data-python.html#visualizing-the-data-with-matplotlib-and-pacoty",
    "title": "Analyzing Equity long Term Returns with Python",
    "section": "Visualizing the Data with Matplotlib and Pacoty",
    "text": "Visualizing the Data with Matplotlib and Pacoty\nNext, we will create a chart comparing the nominal equity returns, real equity returns, and real GDP growth using Matplotlib and the Pacoty stylesheet: python\n\n\nCode\ndata\n\n\n\n\n\n\n  \n    \n      \n      Date\n      P\n      D\n      E\n      CPI\n      Fraction\n      Rate GS10\n      Price\n      Dividend\n      Price.1\n      ...\n      CAPE\n      Unnamed: 13\n      TR CAPE\n      Unnamed: 15\n      Yield\n      Returns\n      Returns.1\n      Real Return\n      Real Return.1\n      Returns.2\n    \n  \n  \n    \n      0\n      1871.01\n      4.44\n      0.26\n      0.4\n      12.464061\n      1871.041667\n      5.32\n      107.612654\n      6.301642\n      1.076127e+02\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.004177\n      1.000000\n      0.130609\n      0.092504\n      0.038106\n    \n    \n      1\n      1871.02\n      4.5\n      0.26\n      0.4\n      12.844641\n      1871.125000\n      5.323333\n      105.835283\n      6.114927\n      1.063449e+02\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.004180\n      0.974424\n      0.130858\n      0.094635\n      0.036224\n    \n    \n      2\n      1871.03\n      4.61\n      0.26\n      0.4\n      13.034972\n      1871.208333\n      5.326667\n      106.839235\n      6.025640\n      1.078582e+02\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.004183\n      0.964209\n      0.130951\n      0.096186\n      0.034765\n    \n    \n      3\n      1871.04\n      4.74\n      0.26\n      0.4\n      12.559226\n      1871.291667\n      5.33\n      114.013268\n      6.253892\n      1.156268e+02\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.004185\n      1.004919\n      0.122056\n      0.090972\n      0.031084\n    \n    \n      4\n      1871.05\n      4.86\n      0.26\n      0.4\n      12.273812\n      1871.375000\n      5.333333\n      119.618062\n      6.399320\n      1.218517e+02\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.004188\n      1.032591\n      0.122638\n      0.089488\n      0.033150\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1824\n      2023.01\n      3960.6565\n      67.35\n      NaN\n      299.17\n      2023.041667\n      3.53\n      3999.346939\n      68.007921\n      2.604715e+06\n      ...\n      28.334813\n      NaN\n      30.691634\n      NaN\n      0.026509\n      0.984746\n      41.286210\n      NaN\n      NaN\n      NaN\n    \n    \n      1825\n      2023.02\n      4079.684737\n      67.78\n      NaN\n      300.84\n      2023.125000\n      3.75\n      4096.669862\n      68.062191\n      2.671794e+06\n      ...\n      28.977514\n      NaN\n      31.409746\n      NaN\n      0.023261\n      1.010600\n      40.430726\n      NaN\n      NaN\n      NaN\n    \n    \n      1826\n      2023.03\n      3968.55913\n      68.21\n      NaN\n      301.675\n      2023.208333\n      3.66\n      3974.051377\n      68.304399\n      2.595537e+06\n      ...\n      28.063455\n      NaN\n      30.441826\n      NaN\n      0.025301\n      1.022361\n      40.746209\n      NaN\n      NaN\n      NaN\n    \n    \n      1827\n      2023.04\n      4100.6\n      NaN\n      NaN\n      302.0925\n      2023.291667\n      3.43\n      4100.600000\n      NaN\n      2.678188e+06\n      ...\n      28.908607\n      NaN\n      31.337301\n      NaN\n      0.026808\n      NaN\n      41.599762\n      NaN\n      NaN\n      NaN\n    \n    \n      1828\n      NaN\n      Apr price is Apr 4th close\n      NaN\n      Dec Estimated\n      Mar/Apr CPI estimated\n      NaN\n      Apr GS10 is Apr 4th value\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n1829 rows × 22 columns\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Set the Pacoty stylesheet\n#plt.style.use('pacoty')\n\n# Create a figure and axis\nfig, ax = plt.subplots()\n\n# Extract the data we need\nyears = data['Date']\nnominal_returns = data['Price.1']\n#real_returns = data['Real S&P Equity Index']\n#gdp_growth = data['Real GDP Growth']\n\n# Plot the data on a logarithmic scale\nax.semilogy(years, nominal_returns, label='Nominal Equity Returns')\n\n# Customize the chart\nax.set_xlabel('Years')\nax.set_ylabel('Returns')\nax.set_title('S&P Equity Index: Nominal Returns, Real Returns, and Real GDP Growth')\nax.legend()\n\n# Show the chart\nplt.show()\n\n\n\n\n\nThis code snippet creates a chart with a logarithmic scale, comparing nominal equity returns, real equity returns, and real GDP growth over time.\nConclusion\nThe resulting chart demonstrates the power of compounded returns and the equity risk premium that has rewarded long-term shareholders. By using Python libraries like requests, pandas, and Matplotlib, we can easily download, process, and visualize financial data to better understand market trends and investment strategies."
  },
  {
    "objectID": "posts/tutorials/en/setting-up-a-python-workstation.html",
    "href": "posts/tutorials/en/setting-up-a-python-workstation.html",
    "title": "Setting up a python development workstation",
    "section": "",
    "text": "## Introduction"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio Geek",
    "section": "",
    "text": "With 20 years of experience in portfolio construction, asset allocation and quantitative research, I have worked across the entire value chain of the asset management and financial markets industry.\nIn this blog, I will document here my findings and experiments, notably in Python, Jupyter and along themes like portfolio optimisation and reproducible research.\nIn my different roles, I have developed and implemented a wide range range of investment solutions, ranging from Exchange Traded Funds (ETFs), derivatives and investment mandates across most asset classes: Equities, Fixed Income, Commodities, Alternative Assets, Multi-Asset portfolios.\n\n\n\n\nPortfolio Optimisation with Python\nRisks and Returns 101\nGood Finance DataSources available to everyone\n\n\n\n\n\nAutomating Powerpoint\nNice Pictures with Python\n\n\n\n\n\nAutomating Powerpoint\nNice Pictures with Python\n\n\n\n\n\nAutomating Powerpoint\nNice Pictures with Python"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "With 20 years of experience in portfolio construction, asset allocation and quantitative research, I have worked across the asset management and capital markets industry’s the value chain.\nIn my different roles, I have developed and implemented a wide range range of investment solutions, ranging from Exchange Traded Funds (ETFs), derivatives and investment mandates across most asset classes: Equities, Fixed Income, Commodities, Alternative Assets, Multi-Asset portfolios.\nFind me on Linkedin\n\nWhy this blog?\nWhat struck me the most when I started my career in finance was the knowledge asymetry between finance professionals and end clients. Whilst this gap reduced considerably since then, thanks to internet and better information provided, many concepts still sound fairly exotic or technical to many investors.\nHere, I will try to demystify financial analysis and provide ideas and starting points in order to put theory into practice.\nIn most articles, you should be able to copy, run and modify the code behind the analysis. This should help you to directly use many of the tools presented. The entire source is available on Github"
  },
  {
    "objectID": "all_posts.html",
    "href": "all_posts.html",
    "title": "All Posts",
    "section": "",
    "text": "10 formules les plus utilisées en finance de marché\n\n\n\n\n\n\n\nfr\n\n\nfinance\n\n\ntutorial\n\n\n101\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nAnalyzing Equity long Term Returns with Python\n\n\n\n\n\n\n\ntutorial\n\n\n101\n\n\nen\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nEstimate Financial Risk\n\n\n\n\n\n\n\ndata-gathering\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nGetting Started with Eurostat API\n\n\n\n\n\n\n\nen\n\n\n101\n\n\ndata\n\n\napi\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2023\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nGetting Started: measuring volatility\n\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nObtenir la valorisation de plusieurs titres avec Python et Alpha Vantage\n\n\n\n\n\n\n\nfr\n\n\nvaluation\n\n\nfundamental\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2023\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nPortfolio optimisation with Python\n\n\n\n\n\n\n\nportfolio-construction\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nSetting up a python development workstation\n\n\n\n\n\n\n\ntutorial\n\n\n101\n\n\nen\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2023\n\n\nVincent D.\n\n\n\n\n\n\n  \n\n\n\n\nVisualising Historical Data\n\n\n\n\n\n\n\npublication-workflow\n\n\n\n\n\n\n\n\n\n\n\nVincent D.\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "risk_and_return.html",
    "href": "risk_and_return.html",
    "title": "Series: Estimating Risk and Return",
    "section": "",
    "text": "Estimate Financial Risk\n\n\n\n\n\n\n\n\n\n\n\n\n0 min\n\n\n\n\n\n\n\n\n10 formules les plus utilisées en finance de marché\n\n\n\n\n\n\n\n\n\n\n\n\n4 min\n\n\n\n\n\n\n\n\nPortfolio optimisation with Python\n\n\n\n\n\n\n\n\n\n\n\n\n7 min\n\n\n\n\n\n\n\n\nGetting Started: measuring volatility\n\n\n\n\n\n\n\n\n\n\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  }
]