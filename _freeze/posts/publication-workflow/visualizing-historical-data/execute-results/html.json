{
  "hash": "dc070ffa67d7e47e951e8ee1f118e477",
  "result": {
    "markdown": "---\ntitle: Visualising Historical Data\ntoc: False\nbadges: True\ncomments: false\nauthor: Vincent D.\ncategories: [publication-workflow]\nseries: Finance and Markets with Python and Jupyter a step-by-step tutorial\n---\n\n![](/pictures/chart-preview.png)\n\n# Visualizing historical data\n\n> \"A quick introduction on how to gather data using Python, Pandas and Pandas_DataReader in order to easily gather historical times from Yahoo Finance. \"\n\n![](photos/banner-data-ipad.png)\n\n## Introduction\n\nTo start our data analysis and portfolio construction journey, we will perform the basic - but essential - task of **getting access** to **time series** and plot them using pandas.\n\n> Tip: This article is written as a Jupyter Notebook. It has been published using [Fastpages](https://portfolio-geek.com/blogging/publishing/workflow/2022/03/06/write-articles-with-jupyter-fastpages.html). The Jupyter notebook is available on GitHub and if you want to, you can run it directly using the provided Binder link displayed at the top of the article.\n\n\n## Load libraries\n\nA key benefit of **Python** is the sheer number of libraries we can leverage to perform a particular task.  Choosing the right library might look a bit overwhelming, and one the goals of this blog is actually to provide the reader my honest view on what makes most sense to perform the usual tasks in my daily work.\n\nThe key module for this article is **[yfinance](https://github.com/ranaroussi/yfinance)**, a fantastic data gathering library that you can find [here](https://github.com/ranaroussi/yfinance) on GitHub.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n#collapse-hide\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport yfinance as yf\nimport datetime as dt\n\n# Note that this change the decimals places inside Jupyter, but not on the website\npd.options.display.float_format = '{:,.1f}'.format\n```\n:::\n\n\n## Get historical data\n\nLet's get ready, and gather some historical data for, say, 4 **Exchange Traded Funds** (ie \"ETFs\", still commonly referred to as \"trackers\" in France): \n- SPY: **S&P 500**\n- GLD: **Gold**\n- AGG: **US Aggregate (US Bonds)**\n- CAC.PA: **CAC 40 (French Equity Index)**\n\nYou might wonder what the first 3 letters actually correspond to? They are the usual identifier for each ETF on the markets, and are often called the **ticker**of the ETF. \n\nTo gather data, you must *de facto* provide one ticker for each security, but if you forgot the ticker, Google is usually your friend!\n\nWe will need define to find a few more **parameters**:\n- The 2 variables start_date and end_date to keep some flexibility, \n- The variable *tickers* will store our ticker list, and pass it as a parameter to Yahoo, in order to specify our query.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n#collapse-hide\n\nstart_date = '2015-01-01'\nend_date = '2022-05-14'\ntickers = ['SPY', 'GLD', 'AGG', 'CAC.PA']\ndf = yf.download(tickers,  start=start_date, end=end_date)\n\n# This ones keep the decimals to one on the website. \n# This is especially useful to print dataframes.\ndf = df.round(decimals=2)\n\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[                       0%                       ]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[                       0%                       ]\r[                       0%                       ]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[*********************100%***********************]  4 of 4 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\n\n\n## Visual data check\n\nBy default, Yahoo Finance provides us with several fields, not all of them will be useful in this introduction, and we will perform some further filtering below.\n\nTo quickly check the status of what we now have, note the use of the **tail()** function below.\n\n[Pandas tail() function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndf.tail(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Adj Close</th>\n      <th colspan=\"4\" halign=\"left\">Close</th>\n      <th colspan=\"2\" halign=\"left\">High</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">Low</th>\n      <th colspan=\"4\" halign=\"left\">Open</th>\n      <th colspan=\"4\" halign=\"left\">Volume</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>AGG</th>\n      <th>CAC.PA</th>\n      <th>GLD</th>\n      <th>SPY</th>\n      <th>AGG</th>\n      <th>CAC.PA</th>\n      <th>GLD</th>\n      <th>SPY</th>\n      <th>AGG</th>\n      <th>CAC.PA</th>\n      <th>...</th>\n      <th>GLD</th>\n      <th>SPY</th>\n      <th>AGG</th>\n      <th>CAC.PA</th>\n      <th>GLD</th>\n      <th>SPY</th>\n      <th>AGG</th>\n      <th>CAC.PA</th>\n      <th>GLD</th>\n      <th>SPY</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-05-11</th>\n      <td>100.3</td>\n      <td>62.6</td>\n      <td>172.8</td>\n      <td>386.2</td>\n      <td>102.8</td>\n      <td>62.6</td>\n      <td>172.8</td>\n      <td>392.8</td>\n      <td>102.8</td>\n      <td>62.6</td>\n      <td>...</td>\n      <td>172.2</td>\n      <td>392.0</td>\n      <td>102.1</td>\n      <td>61.7</td>\n      <td>172.5</td>\n      <td>398.1</td>\n      <td>16,462,000.0</td>\n      <td>45,387.0</td>\n      <td>9,179,600.0</td>\n      <td>142,361,000.0</td>\n    </tr>\n    <tr>\n      <th>2022-05-12</th>\n      <td>100.5</td>\n      <td>62.0</td>\n      <td>170.2</td>\n      <td>385.8</td>\n      <td>103.0</td>\n      <td>62.0</td>\n      <td>170.2</td>\n      <td>392.3</td>\n      <td>103.1</td>\n      <td>62.3</td>\n      <td>...</td>\n      <td>169.9</td>\n      <td>385.1</td>\n      <td>102.9</td>\n      <td>61.4</td>\n      <td>172.1</td>\n      <td>389.4</td>\n      <td>9,015,300.0</td>\n      <td>62,497.0</td>\n      <td>11,626,800.0</td>\n      <td>125,090,800.0</td>\n    </tr>\n    <tr>\n      <th>2022-05-13</th>\n      <td>100.1</td>\n      <td>63.5</td>\n      <td>168.8</td>\n      <td>395.0</td>\n      <td>102.5</td>\n      <td>63.5</td>\n      <td>168.8</td>\n      <td>401.7</td>\n      <td>102.8</td>\n      <td>63.5</td>\n      <td>...</td>\n      <td>168.0</td>\n      <td>395.6</td>\n      <td>102.8</td>\n      <td>62.4</td>\n      <td>168.3</td>\n      <td>396.7</td>\n      <td>6,715,600.0</td>\n      <td>77,603.0</td>\n      <td>13,031,100.0</td>\n      <td>104,174,400.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 24 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe **Adjusted Close** field is returned by Yahoo Finance and is exactly what we are looking for.\n\nAdjusted Close corresponds to the time series containing what we usually call the *total return*, typically **compounding the dividends** with the **price returns**. \n\nThis reflects the total return delivered by the ETF, should the investor reinvest systematically the dividend paid by the ETF by buying more this ETF. This is probably the most useful field when we aim to assess the **long term returns of an asset class**.\n\nTo quickly check the status of what we now have, note the use of the **tail()** function below, which get the last *n* rows of the dataset. Combined with Jupyter's power in printing data, it's probably the fastest way to navigate and check a particular dataset.\n\n[Pandas tail() function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html)\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf['Adj Close'].tail(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGG</th>\n      <th>CAC.PA</th>\n      <th>GLD</th>\n      <th>SPY</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-05-11</th>\n      <td>100.3</td>\n      <td>62.6</td>\n      <td>172.8</td>\n      <td>386.2</td>\n    </tr>\n    <tr>\n      <th>2022-05-12</th>\n      <td>100.5</td>\n      <td>62.0</td>\n      <td>170.2</td>\n      <td>385.8</td>\n    </tr>\n    <tr>\n      <th>2022-05-13</th>\n      <td>100.1</td>\n      <td>63.5</td>\n      <td>168.8</td>\n      <td>395.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Plot the raw time series using the seaborn library\n\nTo quickly check that we got the right data, let's visualise it.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#collapse-hide\nimport seaborn as sns\n\n# Apply the default theme\nsns.set_style('whitegrid')\n\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=df['Adj Close'])\np.set_ylabel(\"Close Price\")\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](visualizing-historical-data_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\n## Plot the normalised the time series\n\nThe chart above is useful, but the vast difference between the ETFs' values makes it a bit hard to actually track each respective time series. \n\nIt would be more effective to **normalise the data**. It's often referred to as \"rebasing\", ie making each time series starting at 100, this will make it much easier to compare.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#collapse-hide\n\n# Normalise the data, which here means for each column to start at 100, with subsequent price development \"scaled\" according to daily returns\nnormalised_ts = (df['Adj Close']/df['Adj Close'].iloc[0, ]*100)\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=normalised_ts)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](visualizing-historical-data_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\n## Rolling window cumulated returns\n\nIt's often easy to get 'seduced' by the compelling long term returns, especially about Equities. And indeed, it was a good thing to be invested in Equities in the long run !\n\nBut 1y returns are usually a good way to keep track of the portfolio, and moreover to see how these returns have developed over time. With a 1y return chart, the notion of risk, ie either fast-changing returns, or - even worse - consistently negative returns, quickly becomes apparent.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# We use pct_change() to calculate the one year return\nts_1y_returns = df['Adj Close'].pct_change(periods=252)\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=ts_1y_returns)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](visualizing-historical-data_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\n## Smoother returns\n\nThe chart above is great, but a bit too busy for my taste. Whilst accurate, there is too much info going on, the noise might reduce our ability to spot real medium terms or breakouts. \n\nThis is where **pandas** starts to be really powerful. The *rolling()* function essentially captures sub-series, with a defined length (here 21 days). By *chaining* the results of rolling() with the *mean* function, ie calculating the arithmetic average, this will provide us in a one-liner with a new series. This generated dataframe contains the time series of the moving average (21 days) for each of our time series.\n\nWhilst this \"chaining\" approach might initially sound obscure, this is **extremely powerful**, especially when factoring in the fact that you just need to change the tickers of the ETFs in the beginning of the article to entirely update the whole analysis ... your turn!\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Normalise the data, which here means for each column to start at 100, with subsequent price development \"scaled\" according to daily returns\nts_1y_returns = df['Adj Close'].pct_change(periods=252).rolling(window=21).mean()\nplt.figure(figsize=(15,6))\np = sns.lineplot(data=ts_1y_returns)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](visualizing-historical-data_files/figure-html/cell-9-output-1.png){}\n:::\n:::\n\n\n## Conclusion\n\nSo that's it for this short intro on data gathering and visualising. In this article, we have gathered, checked, normalised and plot close prices for different ETFs. \n\nThe next step will be to use these function to generate some returns and risk statistics, and start exploring portfolio construction.\n\nSee you in the next article, and stay safe.\n\n\n## Useful Related Links\n\n{% series_list %}\n\nThere is no such thing as \"full tutorial on something\", **knowledge is everywhere**. I found these tutorials pretty handy, check them out too!\n\n- [Seaborn Tutorial](http://seaborn.pydata.org/introduction.html#:~:text=Seaborn%20is%20a%20library%20for,explore%20and%20understand%20your%20data.)\n- [Tutorial on F-Strings](https://www.datacamp.com/community/tutorials/f-string-formatting-in-python)\n\n\n",
    "supporting": [
      "visualizing-historical-data_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}