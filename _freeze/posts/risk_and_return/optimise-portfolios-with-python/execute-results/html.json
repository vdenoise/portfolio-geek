{
  "hash": "8a281e72945ccfa07b5fbf3229ce6413",
  "result": {
    "markdown": "---\ntitle: Portfolio optimisation with Python\ntoc: False\nbadges: True\ncomments: false\nauthor: Vincent D.\ncategories: [portfolio-optimisation]\ntags: [tutorial, markowitz, optimisation, portfolio, construction]\nimage: pictures/portfolio-optimisation.png\nseries: Finance and Markets with Python and Jupyter a step-by-step tutorial\n---\n\n![](pictures/portfolio-optimisation-banner.png)\n\n> Tip: This article is written as a Jupyter Notebook. It has been published using [Fastpages](https://portfolio-geek.com/blogging/publishing/workflow/2022/03/06/write-articles-with-jupyter-fastpages.html). The Jupyter notebook is available on GitHub and if you want to, you can run it directly using the provided Binder link displayed at the top of the article.\n\n{% series_list%}\n\n## Introduction\n\n**Harry Markowitz** is one of the (if not \"the\") fathers of modern portfolio construction and his seminal paper Portfolio Selection{% fn 1 %} has driven an entire research stream. \n\nThe **intuition** behind this paper is that one can combine the information gathered on expected returns, risks and diversification of various assets or asset classes with a view to optimise the risk-return profile of a given portfolio.\n\nIn practice, we typically find a limited stability of the portfolios generated using this approach, especially due the high sensitivity of the portfolio to the expected returns; nonetheless, the insights it provides are very useful and it's a perfect start to see the impact of risk and diversification.\n\nFor this article, we will mostly rely on a fantastic Python library, PyPortfolioOpt {% fn 2%} which will do the optimisation heavy lifting for us.\n\n## Setup\n\n### Loading Libraries\n\nThe main library to load here is indeed **PyPortfolioOpt**{% fn 2%}, and we will rely extensively on it in this article. \n\nWe need the following tools as well:\n- **Pandas**{% fn 3%}: load, filter, sort and pretty much all data wrangling operations;\n- **Numpy**{% fn 4%}: provides most matrix and advanced numerical operations; this library is the calculation backbone for pandas;\n- **Matplotlib**{% fn 5%}: the *de facto* reference library to draw scientific charts;\n- **yfinance**{% fn 6%}: a very handy library to access many different online databases, including Yahoo Finance.\n\n::: {.cell slideshow='{\"slide_type\":\"slide\"}' execution_count=1}\n``` {.python .cell-code}\n#collapse-hide\nimport numpy as np \nimport pandas_datareader.data as web_reader\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport yfinance as yf\n\nfrom pypfopt.efficient_frontier import EfficientFrontier\nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns\n```\n:::\n\n\n### Misc Parameters\n\nIn the code below, we set some variables to adjust the jupyter loo\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n#collapse-hide\n# Note that this change the decimals places inside Jupyter, but not on the website\npd.options.display.float_format = '{:,.1f}'.format\n```\n:::\n\n\n## Defining our Investable Universe\n\nFirst and foremost, we need to define our **Investable Universe** i.e. the set of asset classes that we will allow in our portfolio. \n\nMany investors would typically think about single stocks, but on my side, I am typically looking I am looking here a Long Term Investing, and I would be keen to \n\nSpeaking about asset classes, we need some ETFs to analyse!\n\n> \"Important: Please bear in mind this article if purely for pedagogical purpose and should by no mean be understood as a recommendation or advice. Investing brings risk and in particular risk of loss of capital. I have no intention to recommend anything! I will follow among others this recent article in US News{% fn 7%} and ETF.com{% fn 8%} as sources of inspiration to identify relevant ETFs.\"\n\n\n#### **Equity**\nLet's start with various Equity sub-asset classes:\n\n- **IVV**: iShares Core **S&P 500** ETF representing US Equity Large Cap\n- **SCHA**: Schwab **U.S. Small-Cap** ETF representing US Equity Small Cap\n- **IJH**: iShares Core **S&P Mid-Cap** ETF representing US Equity Mid Cap\n- **SCHD**: Schwab **U.S. Dividend Equity** ETF representing US Equity Dividend (ie US stocks which are deemed to pay higher dividends)\n- **VTI**: Vanguard **Total Stock Market** ETF representing US Equity, with all market cap included\n- **VXUS**: Vanguard **Total International Stock** ETF representing World ex-US equities\n- **EEM**: iShares **MSCI Emerging Markets** ETF representing the Emerging Market Equities\n\n#### **Fixed Income**\nLet's add Fixed Income, which would typically aim to reduce the overall portfolio's volatility:\n\n- **AGG**: iShares Core **U.S. Aggregate Bond** ETFrepresenting the entire US Bond market\n- **GOVT**: iShares **U.S. Treasury Bond** ETF representing the performance of US Government Bonds\n- **VCLT**: Vanguard **Long-Term Corporate Bond** ETF representing the Investment Grade USD denominated bonds.\n\n#### **Alternative Assets**\nLet's add 2 additional asset classes, Gold and Commodities:\n- **GLD**: SPDR **Gold** Trust representing the price of **Gold\n- **PDBC**: Invesco Optimum Yield Diversified **Commodity** Strategy No K-1 ETF** which will represent the performance of the Broad Commodities asset class\n\nEverything in the above is **denominated in US Dollars**, this will make our life easier in what follows, ie we will not need any currency conversion, which is always a bit painfull in the process. \n\n\n## Parameters and data gathering\nI recommend you to read this **[article about data gathering](https://portfolio-geek.com/data/yahoo%20finance/pandas/2022/02/17/gathering_etf_and_stock_historical_data.html)**.\n\nLike we did in this article, we will utilise **pandas_datareader**{% fn 6%} to get historical time series. As mentioned above, we will look at the performance of ETFs, which we will consider as as relevant proxies for their respective asset classes.\n\nYou can of course utilise whatever asset class you want, and take single stocks, funds as historical data points. On my side, I am quite familiar with indices ETFs, and I will go with the selection above. \n\nLast but not least, we need to define the **start_date** and **end_date** for gathering the historical time series. For this study, we will gather 7 years of data.\n\n::: {.cell slideshow='{\"slide_type\":\"skip\"}' execution_count=3}\n``` {.python .cell-code}\n#collapse-hide\n\nstart_date = '2015-03-01'\nend_date = '2022-03-01'\n\n# Define Investable Universe\ninvestable_universe_tickers = ['IVV', 'SCHA', 'IJH', 'SCHD', 'VTI', 'VXUS', 'EEM', 'VCLT', 'AGG', 'GOVT','PDBC','GLD']\n\n# Get Historical Data\ndf = yf.download(investable_universe_tickers, start=start_date, end=end_date)\ndf = df['Adj Close']\n\n# This is required to round the blog's table into 2 decimals, Jupyter's formatting does not apply on the published website\ndf = df.round(decimals=1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[                       0%                       ]\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[********              17%                       ]  2 of 12 completed\r[********              17%                       ]  2 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r[*********************100%***********************]  12 of 12 completed\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\n### Data gathering: **results**\n\nThe request above delivered a **pandas data_frame**, and here is a snapshot of the last 5 rows:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#collapse-hide\ndf.tail(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGG</th>\n      <th>EEM</th>\n      <th>GLD</th>\n      <th>GOVT</th>\n      <th>IJH</th>\n      <th>IVV</th>\n      <th>PDBC</th>\n      <th>SCHA</th>\n      <th>SCHD</th>\n      <th>VCLT</th>\n      <th>VTI</th>\n      <th>VXUS</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-02-24</th>\n      <td>106.4</td>\n      <td>45.4</td>\n      <td>177.1</td>\n      <td>25.0</td>\n      <td>253.0</td>\n      <td>421.6</td>\n      <td>14.3</td>\n      <td>45.0</td>\n      <td>72.0</td>\n      <td>90.5</td>\n      <td>212.3</td>\n      <td>57.5</td>\n    </tr>\n    <tr>\n      <th>2022-02-25</th>\n      <td>106.5</td>\n      <td>46.2</td>\n      <td>176.6</td>\n      <td>25.0</td>\n      <td>260.3</td>\n      <td>430.9</td>\n      <td>14.0</td>\n      <td>46.1</td>\n      <td>74.2</td>\n      <td>91.0</td>\n      <td>217.0</td>\n      <td>58.8</td>\n    </tr>\n    <tr>\n      <th>2022-02-28</th>\n      <td>107.2</td>\n      <td>45.6</td>\n      <td>178.4</td>\n      <td>25.2</td>\n      <td>260.3</td>\n      <td>430.0</td>\n      <td>14.3</td>\n      <td>46.3</td>\n      <td>73.9</td>\n      <td>92.4</td>\n      <td>216.8</td>\n      <td>58.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Normalisation\n\nA table like the above is not very useful: in the absence a of particle knowledge of the ETFs' values, we have no way of knowing if a value is \"high\" or \"low\", hence apart from telling us that the value is a number we have now way to let's try to make this table a bit more insightful.\n\nThe request above delivered a data_frame, and here is a snapshot of the last 5 rows:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#collapse-hide\n# Same table, but this time, normalised\n(df/df.iloc[0, ]*100).round(decimals=1).tail(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGG</th>\n      <th>EEM</th>\n      <th>GLD</th>\n      <th>GOVT</th>\n      <th>IJH</th>\n      <th>IVV</th>\n      <th>PDBC</th>\n      <th>SCHA</th>\n      <th>SCHD</th>\n      <th>VCLT</th>\n      <th>VTI</th>\n      <th>VXUS</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-02-24</th>\n      <td>116.9</td>\n      <td>132.4</td>\n      <td>153.1</td>\n      <td>112.6</td>\n      <td>189.5</td>\n      <td>229.6</td>\n      <td>136.2</td>\n      <td>175.8</td>\n      <td>228.6</td>\n      <td>135.1</td>\n      <td>224.2</td>\n      <td>141.6</td>\n    </tr>\n    <tr>\n      <th>2022-02-25</th>\n      <td>117.0</td>\n      <td>134.7</td>\n      <td>152.6</td>\n      <td>112.6</td>\n      <td>195.0</td>\n      <td>234.7</td>\n      <td>133.3</td>\n      <td>180.1</td>\n      <td>235.6</td>\n      <td>135.8</td>\n      <td>229.1</td>\n      <td>144.8</td>\n    </tr>\n    <tr>\n      <th>2022-02-28</th>\n      <td>117.8</td>\n      <td>132.9</td>\n      <td>154.2</td>\n      <td>113.5</td>\n      <td>195.0</td>\n      <td>234.2</td>\n      <td>136.2</td>\n      <td>180.9</td>\n      <td>234.6</td>\n      <td>137.9</td>\n      <td>228.9</td>\n      <td>142.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis is **much** better.\n\nNow we can at least see that:\n- **US Equities** (e.g. IVV) had a **fantastic ride since 2015**;\n- Government bonds (e.g. GOVT) under-performed;\n- Commodities (PDBC) and Gold (GLD) had several rough years as well, with recent massive pick-up in the current geopolitical context.\n\n\n### Visualise asset classes' returns\nBeing able to sanity check the data is very important, and it's often more efficient with a quick chart.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n#collapse-hide\n\n# Normalise to 100\nnormalised_data = (df/df.iloc[0, ]*100)\n\n# A bit of data wrangling\ntransposed_data = normalised_data.tail(1).reset_index().transpose()\ntransposed_data = transposed_data.iloc[1:len(transposed_data)]\ntransposed_data = transposed_data.rename(columns={0: \"Last Value\"})\n\n# We want a bar chart sorted by decreaseing values\ntransposed_data = transposed_data.sort_values(by=\"Last Value\", ascending=False)\n\n# Theming Seaborn results\nsns.set_theme()\n\n# Draw\ntransposed_data.plot.bar(figsize=(10, 6))\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\n### Draw the **wealth curve**\n\nThe table above is useful, but when it comes to grasping and long term risks and returns, a chart is worth a thousand words.\n\nA very common issue when charting multiple time series is the very different stock levels, and this can make the chart hard to read.\n\nThis is why we will once again normalise the data. \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#collapse-hide\n\n# Theming Seaborn results\nsns.set_theme()\n\n# Plot the time series\nplt.figure(figsize=(12,6))\n\n# Legends and Axis titles\np = sns.lineplot(data=normalised_data)\np.set_ylabel(f\"Close Price, Basis 100 in {start_date}\")\npass\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\n## Estimate risk and return\n\nIn <u>Markowitz 1952</u>{% fn 1 %}, the optimal portfolio is obtained as a function of *expected* returns and *expected* risks of the portfolio. This takes a strong assumption that we have a \"crystal ball\", or at least access to a predictive model, which at this stage is well beyond this article.\n\nFor this first example, we will rely on historical parameters estimation, which precisely means that we expect the past to be a good prediction of what might happen in the future. \n\n### Volatility\n\nThere are many ways to estimate the volatility, and I will only cover the simplest approach. \n\nWe have access to daily close prices of the ETFs, hence we could look at the standard deviation of **daily** returns. In theory this would utilise most of the data we have access to, which is a good thing. In practice, and especially when looking at asset classes which can be observed with an **8 to 12 hours** time difference which might lead the \"sample volatility\" to become inconsistent between 2 asset classes. This is even more important for estimating the **correlation**.\n\nPractitioners often use **weekly returns** to alleviate this issue, and we will do the same here, and as such calculate the returns using a *resampled* time series. To calculate the **annualized volatility** requires an additional factor in this case the square root of 52. Why this? \n\nVolatility is essential to option traders, and when pricing options, practitioners often model asset prices as **Wiener processes**(number of weeks in a year) {% fn 9 %}. The variance of a Wiener process is proportional to the time, and the volatility is the square root of the the variance, which gives us that to convert standard deviation of weekly returns into an *annualized* figure, we need to multiply our results by the square root of the number of weeks in a year (more on Wiener processes here {% fn 9 %}).\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nweekly_returns = df.resample(\"W\").last().pct_change()\n((weekly_returns.std()*math.sqrt(52)*100).sort_values()).plot.bar();\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-9-output-1.png){}\n:::\n:::\n\n\nAs one could have guessed, on the left of the chart above, we can find the low volatility asset classes (e.g. Government Bonds, Investment Grade Bonds), whereas on the right we have high volatility asset classes (Mid Cap and Small Cap Equities).\n\n## Correlation\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nsns.heatmap(weekly_returns.corr());\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-10-output-1.png){}\n:::\n:::\n\n\n::: {.cell slideshow='{\"slide_type\":\"skip\"}' tags='[]' execution_count=10}\n``` {.python .cell-code}\n#collapse-hide\nfrom pypfopt import risk_models\nfrom pypfopt import plotting\n\n# Calculate expected returns and sample covariance\nmu = expected_returns.mean_historical_return(df)\nsample_cov = risk_models.sample_cov(df, frequency=252)\n\nS = risk_models.CovarianceShrinkage(df).ledoit_wolf()\n```\n:::\n\n\n## The main results: Efficient Frontier & Maximum Sharpe Portfolio\n\n### Calculate and draw the efficient frontier\n\nWith expected returns and risk estimated, we are ready to utilise PyPortfolioOpt's optimiser to draw the **efficient frontier**.\n\nThe idea behind the efficient frontier{% fn 1 %} is relatively simple: \n- For **each level of investor's risk**, there is an optimal portfolio which is expected to deliver the **highest level of return**; or conversely\n- For **each level of investor's return**, there is an optimal portfolio which is expected to deliver the **lowest level of return**.\n\n::: {.cell slideshow='{\"slide_type\":\"skip\"}' tags='[]' execution_count=11}\n``` {.python .cell-code}\n#collapse-hide\nef = EfficientFrontier(mu, sample_cov)\n\n# We create 2 efficient frontiers\nfig, ax = plt.subplots()\nplotting.plot_efficient_frontier(ef, ax=ax, show_assets=True)\nax.set_title(\"Asset Classes & Efficient Frontier\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\n\n### Add the Maximum Sharpe portfolio\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n#collapse-hide\n\n# Find and plot the tangency portfolio\nfig2, ax = plt.subplots()\nef2 = EfficientFrontier(mu, S) \nplotting.plot_efficient_frontier(ef2, ax=ax, show_assets=True)\n\nef3 = EfficientFrontier(mu, S) \n\nef3.max_sharpe()\nret_tangent, std_tangent, _ = ef3.portfolio_performance()\nax.scatter(std_tangent, ret_tangent, marker=\"*\", s=100, c=\"r\", label=\"Max Sharpe\")\nax.set_title(\"Asset Classes, Efficient Frontier & Max Sharpe portfolio\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-13-output-1.png){}\n:::\n:::\n\n\n### Calculate random portfolios\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n#collapse-hide\n\n# Plot random portfolios\nfig2, ax = plt.subplots()\nn_samples = 10000\nw = np.random.dirichlet(np.ones(len(mu)), n_samples)\nrets = w.dot(mu)\nstds = np.sqrt((w.T * (S @ w.T)).sum(axis=0))\nsharpes = rets / stds\nax.scatter(stds, rets, marker=\".\", c=sharpes, cmap=\"viridis_r\")\n\n# Format\nax.set_title(\"Random portfolios, based on the same asset classes\")\n#ax.legend()\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](optimise-portfolios-with-python_files/figure-html/cell-14-output-1.png){}\n:::\n:::\n\n\n## Conclusion\n\nEt voila!\n\nCompared to macros or Excel formulas, this is an amazing improvement, and enables us to customise everything in seconds: historical timeframe, asset classes, etc.\n\nTo deliver a full portfolio optimisation process in such a limited number of lines is truly awesome.\n\nI hope this article provided you some ideas on how to look at portfolio construction.\n\nHappy coding, and happy portfolio construction!\n\n{% series_list %}\n\n## Resources\n\n{{ '[Portfolio Selection](https://www.jstor.org/stable/2975974), Henri Markowitz, 1952 ' | fndetail: 1 }}\n\n{{ '[PyportfolioOpt](https://pyportfolioopt.readthedocs.io/en/latest/), Robert Andrew Martin, 2018' | fndetail: 2}}\n\n{{ '[Pandas](https://pandas.pydata.org/)' | fndetail: 3 }}\n\n{{ '[Numpy](https://numpy.org/)' | fndetail: 4 }}\n\n{{ '[Matplolib](https://matplotlib.org/)' | fndetail: 5}}\n\n{{ '[Pandas_datareader](https://pandas-datareader.readthedocs.io/en/latest/#)' | fndetail: 6}}\n\n{{ '[US News, 7 Best Long-Term ETFs to Buy and Hold, 25 Feb 2022](https://money.usnews.com/investing/stock-market-news/slideshows/7-of-the-best-etfs-to-buy-for-long-term-investors)' | fndetail: 7}}\n\n{{ '[ETF.com](https://www.etf.com/)' | fndetail: 8}}\n\n{{ '[Wikipedia.com / Wiener Processes](https://en.wikipedia.org/wiki/Wiener_process)' | fndetail: 9}}\n\n\n",
    "supporting": [
      "optimise-portfolios-with-python_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}